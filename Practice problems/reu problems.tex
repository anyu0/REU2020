\documentclass[12pt]{article}
\usepackage{ragged2e}
\usepackage[margin=1in]{geometry}
\usepackage{amsthm, hhline, enumitem}
\usepackage{stmaryrd}
\usepackage{amsmath, amssymb, graphicx}
\newtheorem{theorem}{Theorem}
\newtheorem*{theorem*}{Theorem}
\DeclareMathOperator{\ex}{\mathbb{E}}
\DeclareMathOperator{\pr}{\mathbb{P}}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\sgn}{sgn}
\begin{document}
	\begin{flushright}
		Summer 2020
	\end{flushright}
	
	\begin{center}
		\LARGE\textbf{REU Practice Problems}
	\end{center}


\section{Topology and measurability}

	We let $\Sigma$ denote a set $\llbracket p, q\rrbracket = \{p,p+1,\dots,q-1,q\}$ for $p\in\mathbb{N}$, $q\in\mathbb{N}\cup\{\infty\}$, and let $\Lambda$ denote an interval in $\mathbb{R}$ with endpoints $a\leq b$. We write $C(X)$ for the space of continuous real-valued functions on $X$ with the topology of compact convergence and the Borel $\sigma$-algebra $\mathcal{C}$. Recall that this topology is generated by the basis of sets
	\[
	B_K(f,\epsilon) := \big\{g\in C(X):\sup_{x\in K} |f(x)-g(x)|<\epsilon\big\},
	\]
	with $K\subset X$ is compact, $f\in C(X)$, and $\epsilon>0$. When $X=\Sigma\times\Lambda$, we write $(C(\Sigma\times\Lambda),\mathcal{C}_\Sigma)$.

	\subsection*{Problem 1}
	
		We aim to construct a metric $d:C(\Sigma\times\Lambda)\times C(\Sigma\times\Lambda)\to [0,\infty)$ which induces the topology of compact convergence on $C(\Sigma\times\Lambda)$. The idea is to obtain a compact exhaustion of $\Sigma\times\Lambda$, i.e., a countable collection of compact sets $K_n\subset\Sigma\times\Lambda$ such that $\bigcup_n K_n = \Sigma\times\Lambda$, and such that every compact subset of $\Sigma\times\Lambda$ is contained in some $K_n$. We then construct $d$ from the sup-metrics on each of these sets $K_n$. We define the sets
		\[
		K_n := \Sigma_n \times \Lambda_n = \llbracket p, q_n\rrbracket \times [a_n,b_n]
		\]
		as follows. We let $q_n = \min(p+n,q)$. If $a\in\Lambda$, i.e, $\Lambda$ is closed at the left, then $a_n=a$ for all $n$, and likewise $b_n=b$ if $b\in\Lambda$. If $a\notin\Lambda$, we let $a_n\in\mathbb{R}$, $a_n>a$ be a sequence decreasing to $a$, for instance $a_n=a+\frac{1}{n}$ if $a>-\infty$, or $a_n=-n$ if $a_n=-\infty$. If $b\notin\Lambda$, we let $b_n\nearrow b$. In any case, we see that the sets $K_1\subset K_2\subset\cdots\subset\Sigma\times\Lambda$ are compact, they cover $\Sigma\times\Lambda$, and any compact subset $K$ of $\Sigma\times\Lambda$ is contained in all $K_n$ for sufficiently large $n$.
		
		We now define, for each $n$ and $f,g\in C(\Sigma\times\Lambda)$,
		\[
		d_n(f,g) := \sup_{(i,t)\in K_n} |f(i,t)-g(i,t)|,\quad d_n'(f,g) := \min\{d_n(f,g), 1\} 
		\]
		Clearly each $d_n$ is nonnegative and satisfies the triangle inequality, and it is then easy to see that the same properties hold for $d_n'$. Furthermore, $d_n'\leq 1$, so we can define
		\[
		d(f,g) := \sum_{n=1}^\infty 2^{-n} d_n'(f,g).
		\]
		We first observe that $d$ is a metric on $C(\Sigma\times\Lambda)$. Indeed, it is nonnegative, and if $f=g$, then each $d_n'(f,g)=0$, so the sum is 0. Conversely, if $f\neq g$, then since the $K_n$ cover $\Sigma\times\Lambda$, we can choose $n$ large enough so that $K_n$ contains an $x$ with $f(x)\neq g(x)$. Then $d_n'(f,g)\neq 0$, and hence $d(f,g)\neq 0$. The triangle inequality holds for $d$ since it holds for each $d_n'$.
		
		Now we prove that the topology $\tau_d$ on $C(\Sigma\times\Lambda)$ induced by $d$ is the same as the topology of compact convergence, which we will denote $\tau_c$. First, choose $\epsilon>0$ and $f\in C(\Sigma\times\Lambda)$. Let $g\in B^d_\epsilon(f)$, i.e., $d(f,g)<\epsilon$. We will find a set $A_g\in\tau_c$ such that $g\in A_g\subset B^d_\epsilon(f)$. Let $\delta := d(f,g)$, and choose $n$ large enough so that $\sum_{k>n} 2^{-k} < \frac{\epsilon-\delta}{2}$. Define $A_g := B_{K_n}(g,\frac{\epsilon-\delta}{n})$, and suppose $h\in A_g$. Then since $K_m\subseteq K_n$ for $m\leq n$, we have
		\begin{align*}
		d(f,h) &\leq d(f,g) + d(g,h)\\
		&\leq \delta + \sum_{k=1}^n 2^{-k}d_n(g,h) + \sum_{k>n} 2^{-k}\\
		&\leq \delta + \frac{\epsilon-\delta}{2} + \frac{\epsilon-\delta}{2} = \epsilon.
		\end{align*}
		Therefore $g\in A_g\subset B^d_\epsilon(f)$. It follows that $B^d_\epsilon(f)\in \tau_c$. Indeed, we can write
		\[
		B^d_\epsilon(f) = \bigcup_{g\in B^d_\epsilon(f)} A_g,
		\]
		a union of elements of $\tau_c$. This proves that $\tau_d\subseteq\tau_c$.
		
		To prove the converse, let $K\subset\Sigma\times\Lambda$ be compact, $f\in C(\Sigma\times\Lambda)$, and $\epsilon>0$. Choose $n$ so that $K\subset K_n$, and let $g\in B_K(f,\epsilon)$ and $\delta:= \sup_{x\in K} |f(x)-g(x)|$. If $d(g,h) < 2^{-n}(\epsilon-\delta)$, then $d_n'(g,h) \leq 2^n d(g,h) < \epsilon-\delta$, hence $d_n(g,h) < \epsilon-\delta$. It follows that
		\begin{align*}
		\sup_{x\in K} |f(x)-h(x)| &\leq \delta + \sup_{x\in K} |g(x)-h(x)| \leq \delta + d_n(g,h)\\
		&\leq \delta + \epsilon-\delta = \epsilon.
		\end{align*}
		Thus $g\in B^d_{2^{-n}(\epsilon-\delta)}(f) \subset B_K(f,\epsilon)$. It follows that $\tau_c\subseteq \tau_d$, and we conclude that $\tau_d = \tau_c$.
		
		Next, we show that $(C(\Sigma\times\Lambda), d)$ is a complete metric space. Let $(f_n)_{n\geq 1}$ be Cauchy with respect to $d$. Then we claim that $(f_n)$ must be Cauchy with respect to $d_n'$, on each $K_n$. Indeed, $d(f_\ell, f_m) \geq 2^{-n}d_n'(f_\ell, f_m)$, so if $(f_n)$ were not Cauchy with respect to $d_n'$, it would not be Cauchy with respect to $d$ either. Thus $(f_n)$ is uniformly Cauchy on each $K_n$, and hence converges uniformly to a limit $f^{K_n}$ on each $K_n$. Since the limit must be unique at each point of $\Sigma\times\Lambda$, we have $f^{K_n}(x) = f^{K_m}(x)$ if $x\in K_n\cap K_m$. Since $\bigcup K_n = \Sigma\times\Lambda$, we obtain a well-defined function $f$ on all of $\Sigma\times\Lambda$ given by $f(x)=f^{K_n}(x)$, where $x\in K_n$. Given any compact $K\subset \Sigma\times\Lambda$, if $n$ is large enough so that $K\subset K_n$, then because $f_n \to f^{K_n} = f|_{K_n}$ uniformly on $K_n$, we have $f_n \to f^{K_n}|_K = f|_K$ uniformly on $K$. That is, for any $K\subset\Sigma\times\Lambda$ compact and $\epsilon>0$, we have $f_n \in B_K(f,\epsilon)$ for all sufficiently large $n$. Therefore $(f_n)$ converges to $f$ in the topology of compact convergence, and equivalently in the metric $d$.
		
		Lastly, we prove separability, following example 1.3 in Billingsley, \textit{Convergence of Probability Measures}. For each pair of positive integers $n,k$, let $D_{n,k}$ be the subcollection of $C(\Sigma\times\Lambda)$ consisting of polygonal functions that are piecewise linear on $\{j\}\times I_{n,k,i}$ for each $j\in\Sigma_n$ and each subinterval 
		\[
		I_{n,k,i} := [a_n+\tfrac{i-1}{k}(b_n-a_n), a_n+\tfrac{i}{k}(b_n-a_n)], \quad 1\leq i\leq k,
		\] 
		taking rational values at the endpoints of these subintervals, and extended linearly to all of $\Lambda = [a,b]$. Then $D := \bigcup_{n,k} D_{n,k}$ is countable, and we claim that it is dense in the topology of compact convergence. To see this, let $K\subset\Sigma\times\Lambda$ be compact, $f\in C(\Sigma\times\Lambda)$, and $\epsilon>0$, and choose $n$ so that $K\subset K_n$. Since $f$ is uniformly continuous on $K_n$, we can choose $k$ large enough so that $|f(j,t) - f(j, a_n + \frac{i}{k}(b_n-a_n))| < \epsilon/2$ for $j\in\Sigma_n$ and $1\leq i\leq k$. We then choose $g\in \bigcup_k D_{n,k}$ with $|g(j,a_n + \frac{i}{k}(b_n-a_n)) - f(j,a_n + \frac{i}{k}(b_n-a_n))| < \epsilon/2$. Then $f(j,t)$ is within $\epsilon$ of both $g(j,a_n + \frac{i-1}{k}(b_n-a_n))$ and $g(j,a_n + \frac{i}{k}(b_n-a_n))$. Since $g(j,t)$ lies between these two values, $f(j,t)$ is with $\epsilon$ of $g(j,t)$ as well. In summary,
		\[
		\sup_{(j,t)\in K} |f(j,t)-g(j,t)| \leq \sup_{(j,t)\in K_n} |f(j,t)-g(j,t)| < \epsilon,
		\] 
		so $g\in B_K(f,\epsilon)$. This proves that $D$ is a countable dense subset of $C(\Sigma\times\Lambda)$. We conclude that $(C(\Sigma\times\Lambda),\tau_c)$ is a Polish space.
		
		
	\section*{Problem 2}
	
		Let $(\Omega,\mathcal{F},\pr)$ be a probability space and $X,Y$ random variables on $(\Omega,\mathcal{F},\pr)$ taking values in $C(\Sigma\times\Lambda)$, where $\Sigma = \llbracket 1, N\rrbracket$ with $N\in\mathbb{N}$ or $N=\infty$. We consider the collection $\mathcal{S}_X$ of sets of the form
		\[
		\{\omega\in\Omega : X(\omega)(i_1,t_1)\leq x_1,\dots,X(\omega)(i_n,t_n)\leq x_n\} = \bigcap_{k=1}^n X(i_k,t_k)^{-1}(-\infty,x_k],
		\] 
		ranging over all $n\in\mathbb{N}$, $(i_1,t_1),\dots,(i_n,t_n)\in \Sigma\times\Lambda$, and $x_1,\dots,x_n\in\mathbb{R}$. We first prove that $\mathcal{S}_X \subset \mathcal{F}$. We can write 
		\[
		\{X(i_k,t_k)\leq x_k\} = X^{-1}(\{f\in C(\Sigma\times\Lambda):f(i_k,t_k)\leq x_k\}).
		\]
		We claim that the set $\{f\in C(\Sigma\times\Lambda):f(i_k,t_k)\leq x_k\}$ is closed in the topology of compact convergence. If $f_n(i_k,t_k)\leq x_k$ for all $n$ and $f_n\to f$ in the topology of compact convergence, then by taking limits on a compact set containing $(i_k,t_k)$, we find $f(i_k,t_k)\leq x_k$ as well. This proves the claim, and it follows from the measurability of $X$ that $\{X(i_k,t_k)\leq x_k\} = X^{-1}(\{f(i_k,t_k)\leq x_k\})\in\mathcal{F}$. The finite intersection is thus also in $\mathcal{F}$, proving that $\mathcal{S}_X \subset \mathcal{F}$. On the other hand, it is clear that $\{\omega\in\Omega:X(\omega)\in A\} = X^{-1}(A)\in\mathcal{F}$ for any $A\in\mathcal{C}_\Sigma$ since $X$ is measurable.
		
		Now we prove that $\mathbb{P}|_{\mathcal{S}_X}$ determines the distribution $\mathbb{P}\circ X^{-1}$. To do so, note that $\mathcal{S}_X = \sigma(\{X^{-1}(A) : A\in\mathcal{S}\})$, where $\mathcal{S}$ is the collection of cylinder sets
		\[
		\{f\in C(\Sigma\times\Lambda) : f(i_1,t_1)\in A_1, \dots, f(i_n,t_n) \in A_n\}, \quad A_1,\dots,A_n\in\mathcal{B}(\mathbb{R}). 
		\]
		This follows from the fact that $\mathcal{B}(\mathbb{R})$ is generated by intervals of the form $(-\infty,x]$. Furthermore, this fact, along with the fact proven above that $\{f(i_k,t_k)\in (-\infty,x_k]\}$ is closed, show that $\mathcal{S}\subset\mathcal{C}_\Sigma$. Observe that the intersection of two elements of $\mathcal{S}$ is clearly another element of $\mathcal{S}$, so $\mathcal{S}$ is a $\pi$-system. We now argue that $\mathcal{S}$ generates the Borel sets, i.e., $\sigma(\mathcal{S}) = \mathcal{C}_\Sigma$. Since $\mathcal{S}\subset \mathcal{C}_\Sigma$, we have $\sigma(\mathcal{S})\subseteq \mathcal{C}_\Sigma$. To prove the opposite inclusion, let $K\subset\Sigma\times\Lambda$ be compact, $f\in C(\Sigma\times\Lambda)$, and $\epsilon>0$, and let $H$ be a countable dense subset of $K$. (Recall that every compact metric space is separable, and $K$ is homeomorphic to a product of finitely many compact sets in $\mathbb{R}$, which are metrizable. So $K$ is separable.) We claim that
		\[
		B_K(f,\epsilon) = \bigcup_{n=1}^\infty\,\bigcap_{(i,t)\in H} \{g\in C(\Sigma\times\Lambda) : g(i,t) \in  (f(i,t)-(1-2^{-n})\epsilon, f(i,t) + (1-2^{n})\epsilon)\}.
		\]
		Indeed, if $g\in B_K(f,\epsilon)$, i.e., $\sup_{(i,t)\in K} |g(i,t)-f(i,t)| < \epsilon$. Then since $1-2^{-m}\nearrow 1$, we can choose $m$ large enough so that 
		\[
		|g(i,t)-f(i,t)| < (1-2^{-n})\epsilon
		\] 
		for all $(i,t)\in K$ (in particular with $(i,t)\in H$). Conversely, suppose $g$ is in the set on the right. Then since $g$ is continuous and $H$ is dense in $K$, we find that for some $n\geq 1$,
		\[
		|g(i,t)-f(i,t)| \leq (1-2^{-n})\epsilon < \epsilon
		\]
		for all $(i,t)\in K$. Hence $g\in B_K(f,\epsilon)$. This proves the claim. Since $H$ is countable, $B_K(f,\epsilon)$ is formed from countably many unions and intersections of sets in $\mathcal{S}$, thus $B_K(f,\epsilon)\in\sigma(\mathcal{S})$.
		
		Now by problem 1, the topology generated by the basis $\mathcal{A} = \{B_K(f,\epsilon)\}$ is separable and metrizable. The balls of rational radii centered at points of a countable dense subset then give a (different) countable basis $\mathcal{B}$ for the same topology. We claim that this implies that every open set is a \textit{countable} union of sets $B_K(f,\epsilon)$. To see this, let $B\in\mathcal{B}$, and write $B=\bigcup_{\alpha\in I} A_\alpha$, for sets $A_\alpha\in\mathcal{A}$. Then for each $x\in B$, pick $\alpha_x \in I$ such that $x\in A_{\alpha_x}$. Since $\mathcal{B}$ is a basis, there is a set $B_x \in \mathcal{B}$ with $x\in B_x\subseteq A_{\alpha_x}$. Then $B = \bigcup_{x\in B} A_{\alpha_x}$. Note that if $y\in B_y \subseteq A_{\alpha_y}$ and $B_y=B_x$, then in fact $y\in A_{\alpha_x}$, so we can remove $A_{\alpha_y}$ from the union. In other words, we can choose the $A_{\alpha_x}$ so that each corresponds to exactly one $B_x$. But there are only countably many distinct sets $B_x$, so we see that $B$ is a countable union of elements of $\mathcal{A}$. Since every open set can be written as a countable union of elements of $B$, this proves the claim. Since $\mathcal{A}\subseteq\sigma(\mathcal{S})$ by the above, it follows that every open set is in $\sigma(\mathcal{S})$, and consequently so is every Borel set, i.e., $\mathcal{C}_\Sigma \subseteq \sigma(\mathcal{S})$.
		
		In summary, we have shown that the collection $\mathcal{S}$ is a $\pi$-system generating $\mathcal{C}_\Sigma$, so the probability measure $\mathbb{P}\circ X^{-1}$ on $\mathcal{C}_\Sigma$ is uniquely determined by its restriction to $\mathcal{S}$. Suppose
		\begin{align*}
		&\mathbb{P}\left(\{\omega\in\Omega : X(\omega)(i_1,t_1)\leq x_1,\dots,X(\omega)(i_n,t_n)\leq x_n\}\right) =\\
		&\qquad\qquad \mathbb{P}\left(\{\omega\in\Omega : Y(\omega)(i_1,t_1)\leq x_1,\dots,Y(\omega)(i_n,t_n)\leq x_n\}\right)
		\end{align*}
		for all $(i_1,t_1), x_1,\dots,x_n$. This says that the two probability measures $\mathbb{P}\circ X^{-1}$ and $\mathbb{P}\circ Y^{-1}$ agree on $\mathcal{S}$. Then they must agree on all of $\mathcal{C}_\Sigma$, i.e.,
		\[
		\mathbb{P}\left(\{\omega\in\Omega : X(\omega)\in A\}\right) = \mathbb{P}\left(\{\omega\in\Omega : Y(\omega)\in A\}\right)
		\]
		for all $A\in\mathcal{C}_\Sigma$. In other words, the law of a line ensemble is determined by its finite dimensional distributions.
		

\section{Algebra}

	\subsection*{Problem 3}
	
	\subsection*{Problem 4}


\section{Weak convergence}

\subsection*{Problem 5}
(1)$\phi_{n}(t)=\mathbb{E}[e^{itY_{n}}]=\sum\limits_{k=0}^{\infty}p_{n}(1-p_{n})^{k}e^{itp_{n}k}=\frac{p_{n}}{1-(1-p_{n})e^{itp_{n}}}$. Then, $$\lim\limits_{n\rightarrow\infty}\phi_{n}(t)=\lim\limits_{x\rightarrow 0}\frac{x}{1-(1-x)e^{itx}}=\lim\limits_{x\rightarrow 0}\frac{1}{1-it(1-x)e^{itx}}(\text{L'Hospital})=\frac{1}{1-it},$$
which is the characteristic function of exponential random variable with parameter $1$. Therefore, $Y_{n}$ weakly converges to $Z\sim Exp(1)$.\\
(2) Notice that 
\begin{align*}
\frac{d}{d q_{n}}\mathbb{E}[Y_{n}^{k-1}]&=\frac{d}{d q_{n}}[\sum_{x=0}^{\infty}p_{n}^{k-1}x^{k-1}p_{n}q_{n}^{x}]=	\sum_{x=0}^{\infty}x^{k-1}[-kp_{n}^{k-1}q_{n}^{x}+p_{n}^{k}x q_{n}^{x-1}]\\
&=-\frac{k}{p_{n}}\sum_{x=0}^{\infty}(p_{n}x)^{k-1}p_{n}q_{n}^{x}+\frac{1}{p_{n}q_{n}}\sum_{x=0}^{\infty}(p_{n}x)^{k}p_{n}q_{n}^{x}\\
&=-\frac{k}{p_{n}}\mathbb{E}[Y_{n}^{k-1}]+\frac{1}{p_{n}q_{n}}\mathbb{E}[Y_{n}^{k}]
\end{align*}
Therefore, we have $$\mathbb{E}[Y_{n}^{k}]=p_{n}q_{n}\frac{d}{d q_{n}}\mathbb{E}[Y_{n}^{k-1}]+k\cdot q_{n}\mathbb{E}[Y^{k-1}]$$
Let $p_{n}\rightarrow 0$, we get $\lim\limits_{n\rightarrow\infty}\mathbb{E}[Y_{n}^{k}]=k\cdot \lim\limits_{n\rightarrow\infty}\mathbb{E}[Y_{n}^{k-1}]$.
Since $\lim\limits_{n\rightarrow\infty}\mathbb{E}[Y_{n}]=\lim\limits_{n\rightarrow\infty}p_{n}\cdot\frac{1-p_{n}}{p_{n}}=1$, we obtain: $$\lim\limits_{n\rightarrow\infty}\mathbb{E}[Y_{n}^k]=k!$$
which is the $k$-$th$ moment of exponential random variable with parameter $1$.


(3) For a bounded continuous function $f$ which is bounded by $M$, $$\mathbb{E}[f(Y_{n})]=\sum_{k=0}^{\infty}f(kp_{n})p_{n}(1-p_{n})^{k}\leqslant \frac{M(1-p_{n})}{p_{n}}$$ is well-defined.
Notice that $(1-p_{n})^{k}=e^{kln(1-p_{n})}=e^{-kp_{n}+o(p_{n})}=e^{-kp_{n}}(1+o(p_{n}))$, so $$\mathbb{E}[f(Y_{n})]=\sum_{k=0}^{\infty}f(kp_{n})p_{n}e^{-kp_{n}}+\sum_{k=0}^{\infty}f(kp_{n})p_{n}e^{-kp_{n}}o(p_{n})$$
For the first term, $$\lim_{n\rightarrow\infty}\sum_{k=0}^{\infty}f(kp_{n})p_{n}e^{-kp_{n}}=\int_{0}^{\infty}f(x)e^{-x}dx=\mathbb{E}[f(Y)]$$
by definition of integral, and here we use the continuity of function $f$. For the second term, it converges to $0$. Thus, $\mathbb{E}[f(Y_{n})]\xrightarrow{n\rightarrow\infty}\mathbb{E}[f(Y)]$.\\
(4) Consider $\frac{1}{p_{n}}\cdot p_{n}(1-p_{n})^{k_{n}}$, where $k_{n}=x\cdot\frac{1}{p_{n}}$. Notice that $\frac{1}{p_{n}}\cdot p_{n}(1-p_{n})^{k_{n}}=e^{\frac{x}{p_{n}}ln(1-p_{n})}=e^{\frac{x}{p_{n}}}(-p_{n}+o(p_{n}))=e^{-x+o(1)}$. Consider 
\begin{align*}
\mathbb{P}(a\leqslant Y_{n}\leqslant b) &= \mathbb{P}(\frac{a}{p_{n}}\leqslant X_{n}\leqslant \frac{b}{p_{n}})\\
&=\sum_{k=m_{n}}^{M_{n}}\mathbb{P}(X_{n}=k)\quad(\text{where $m_n=[\frac{a}{p_{n}}]+1$, $M_{n}=[\frac{b}{p_{n}}]$})\\
&= \sum_{k=m_{n}}^{M_{n}}p_{n}e^{x_{k}+o(1)}\quad(\text{where $x_{k}=p_{n}k$ and $x_{k}-x_{k-1}=p_{n}$})\\
&\approx\sum_{k=m_{n}}^{M_{n}}\int_{x_{k}-\frac{1}{2}p_{n}}^{x_{k}+\frac{1}{2}p_{n}}e^{-x}dx=\int_{x_{m_{n}}-\frac{1}{2}p_{n}}^{x_{M_{n}}+\frac{1}{2}p_{n}}e^{-x}dx\\
& \rightarrow \int_{a}^{b}e^{-x}dx\quad(\text{as $n\rightarrow\infty$})
\end{align*}
Therefore, $\lim\limits_{n\rightarrow\infty}\mathbb{P}(Y_{n}\leqslant x)=\int_{-\infty}^{x}e^{-u}du$.

\subsection*{Problem 6}
(1)\begin{align*}
\phi_{n}(t)&= \mathbb{E}[e^{itX_{n}}]=\sum_{k=0}^{N_{n}}\binom{N_{n}}{k}p_n^{k}(1-p_n)^{N_{n}-k}e^{itk}\\
&=(p_{n}e^{it}+(1-p_n))^{N_{n}}\\
&=e^{N_{n}ln(1+p_{n}(e^{it}-1))}
\end{align*}
As $p_n\rightarrow 0$, $N_{n}\rightarrow\infty$, $p_{n}N_{n}\rightarrow \lambda$, we have $ln(1+p_{n}(e^{it}-1))\rightarrow p_{n}(e^{it}-1)$, and $\lim\limits_{n\rightarrow\infty}\phi_{n}(t)= e^{\lim\limits_{n\rightarrow\infty}N_{n}p_{n}(e^{it}-1)}=e^{\lambda (e^{it}-1)}$, which is the characteristic function of Poisson distribution. Thus, $X_{n}$ weakly converges to Poisson random variable with parameter $\lambda$.\\
(2) Denote $$P_{k,n}=\frac{N_{n}!}{k!(N_{n}-k)!}\cdot p_{n}^{k}(1-p_{n})^{N_{n}-k}=\frac{(p_{n}N_{n})^{k}}{k!}\cdot \frac{N_{n}!}{N_{n}^{k}(N_{n}-k)!}(1-p_{n})^{N_{n}-k}$$
Notice that $\frac{N_{n}!}{N_{n}^{k}(N_{n}-k)!}=\frac{N_{n}}{N_{n}}\cdot\frac{N_{n}-1}{N_{n}}\cdot\dots\cdot\frac{N_{n}-k+1}{N_{n}}\rightarrow 1$, as $N_{n}\rightarrow\infty$;\\ 
$(1-p_{n})^{N_{n}-k}=e^{(N_{n}-k)ln(1-p_{n})}=e^{(N_{n}-k)(-p_{n}+o(p_{n}))}\rightarrow e^{-\lambda}$, as $n\rightarrow\infty$; \\ and $\frac{(p_{n}N_{n})^{k}}{k!}\rightarrow\frac{\lambda^{k}}{k!}$. Therefore, $P_{k,n}\rightarrow\frac{\lambda^{k}}{k!}e^{-\lambda}$ as $n\rightarrow\infty$. Then, $\mathbb{P}(X_{n}\leqslant x)=\sum_{k=1}^{[x]}P_{k,n}$. Let $n\rightarrow\infty$, $\mathbb{P}(X_{n}\leqslant x)=\sum_{k=1}^{[x]}P_{k,n}\rightarrow\sum_{k=1}^{[x]}\frac{\lambda^{k}}{k!}e^{-\lambda}$ is the distribution of Poisson random variable.

\subsection*{Problem 7}
(1)
\begin{align*}
\phi_{n}(t)&=\mathbb{E}[e^{itY_{n}}]=\sum_{k=0}^{\infty}e^{-n}\frac{n^k}{k!}e^{it\frac{k-n}{\sqrt{n}}}\\
&=\sum_{k=0}^{\infty}\frac{(ne^{it\frac{1}{\sqrt{n}}})^{k}}{k!}e^{-it\sqrt{n}-n}\\
&=e^{-it\sqrt{n}-n+ne^{it\frac{1}{\sqrt{n}}}}
\end{align*}
Notice that $n(e^{it\frac{1}{\sqrt{n}}}-1)-it\sqrt{n}=n(it\frac{1}{\sqrt{n}}+\frac{1}{2}(it\frac{1}{\sqrt{n}})^2+o(\frac{1}{n}))-it\sqrt{n}=-\frac{1}{2}t^2+o(1)$. Therefore, $\phi_{n}(t)\rightarrow e^{-\frac{1}{2}t^2}$ as $n\rightarrow\infty$, which is the characteristic function of standard normal random variable.\\
(2) Let us consider $\lim\limits_{n\rightarrow\infty}\sqrt{n}\frac{n^{k_{n}}}{k_{n}!}e^{-n}$, where $k_{n}=x\sqrt{n}+n$. By Stirling's formula, $n!\sim\sqrt{2\pi n}n^{n}e^{-n}$. Then,
\begin{align*}
\sqrt{n}\frac{n^{k_{n}}}{k_{n}!}e^{-n} &\sim \sqrt{n}\frac{n^{k_{n}}}{\sqrt{2\pi k_{n}}k_{n}^{k_{n}}e^{-k_{n}}} e^{-n}\\
&=\frac{\sqrt{n}}{\sqrt{2\pi k_{n}}}(\frac{n}{k_{n}})^{k_{n}}e^{k_{n}-n}\\
&=\frac{\sqrt{n}}{\sqrt{2\pi k_{n}}}e^{k_{n}ln(\frac{n}{k_{n}})+k_{n}-n}
\end{align*}
Notice that $k_{n}=x\sqrt{n}+n\sim O(n)$, we know $\lim\limits_{n\rightarrow\infty}\frac{\sqrt{n}}{\sqrt{k_{n}}}=1$;
\begin{align*}
k_{n}ln(\frac{n}{k_{n}})&=k_{n}ln(1-\frac{k_{n}-n}{k_{n}})\quad(\frac{k_{n}-n}{k_{n}}=\frac{x}{x+\sqrt{n}}\sim O(\frac{1}{\sqrt{n}}))\\
&=k_{n}(-\frac{k_{n}-n}{k_{n}}-\frac{1}{2}(\frac{k_{n}-n}{k_{n}})^{2}+o(\frac{1}{n}))\\
&=-k_{n}+n-\frac{1}{2}\frac{n x^2}{x\sqrt{n}+n}+o(1)\\
&=-k_{n}+n-\frac{1}{2}x^2+o(1)
\end{align*}
Therefore, $\sqrt{n}\frac{n^{k_{n}}}{k_{n}!}e^{-n}=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2+o(1)}$.\\
Next, consider: $\mathbb{P}(a\leqslant Y_{n}\leqslant b)=\mathbb{P}(a\sqrt{n}+n\leqslant X_{n}\leqslant b_{n}+n)$. Denote $m_{n}=[a\sqrt{n}+n]+1$, $M_{n}=[b\sqrt{n}+n]$, then
\begin{align*}
\mathbb{P}(a\leqslant Y_{n}\leqslant b)&=\sum_{k=m_{n}}^{M_{n}}\mathbb{P}(X_{n}=k)\\
&=\sum_{k=m_{n}}^{M_{n}}\frac{1}{\sqrt{n}}\frac{1}{\sqrt{2\pi}}e^{-\frac{x_{k}^2}{2}+o(1)}\quad(\text{where $x_{k}=\frac{k-n}{\sqrt{n}}$, $x_{k}-x_{k-1}=\frac{1}{\sqrt{n}}$})\\
&\approx \sum_{k=m_{n}}^{M_{n}}\int_{x_{k}-\frac{1}{2\sqrt{n}}}^{x_{k}+\frac{1}{2\sqrt{n}}} \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx\\
&=\int_{x_{m_{n}}-\frac{1}{2\sqrt{n}}}^{x_{M_{n}}+\frac{1}{2\sqrt{n}}} \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx\\
& \rightarrow \int_{a}^{b}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx
\end{align*}
Therefore, $\lim\limits_{n\rightarrow\infty}\mathbb{P}(Y_{n}\leqslant x)=\int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}e^{-\frac{u^2}{2}}du$.\\
(3) Suppose $Z_{1},Z_{2},\dots, Z_{n}$, \emph{I.I.D}, are Poisson random variables with parameter $1$. Then, $X_{n}=\sum\limits_{k=1}^{n}Z_{k}\sim Poisson(n)$, and $\mathbb{E}(X_{n})=n$, $Var(X_{n})=n$. By Central Limit Theorem, $\frac{X_{n}-n}{\sqrt{n}}\xrightarrow{d}\mathcal{N}(0,1)$.


\section{Tightness}

	\subsection*{Problem 8}
	
		Let $\Lambda\subset\mathbb{R}$ be an interval and $\Sigma = \llbracket 1, N\rrbracket$ with $N\in\mathbb{N}\cup\{\infty\}$. Consider the maps 
		\[
		\pi_i : C(\Sigma\times\Lambda) \to C(\Lambda), \quad \pi_i(F)(x) = F(i,x), \quad i\in\Sigma.
		\]
		Since $C(X)$ with the topology of compact convergence is metrizable by problem 1, to show that the $\pi_i$ are continuous, it suffices to show that if $f_n\to f$ in $C(\Sigma\times\Lambda)$, then $\pi_i(f_n)\to \pi_i(f)$ in $C(\Lambda)$. But this is immediate, since if $f_n\to f$ uniformly on compact subsets of $\Sigma\times\Lambda$, then in particular $f_n(i,\cdot)\to f(i,\cdot)$ uniformly on compact subsets of $\Lambda$.
		
		Let $\mathcal{L}^n$ be a sequence of $\Sigma$-indexed line ensembles on $\Lambda$, i.e., each $\mathcal{L}^n$ is a $C(\Sigma\times\Lambda)$-valued random variable on a probability space $(\Omega,\mathcal{F},\mathbb{P})$. Let $X_i^n := \pi_i(\mathcal{L}^n)$. If $A$ is a Borel set in $C(\Lambda)$, then $(X_i^n)^{-1}(A) = (\mathcal{L}^n)^{-1}(\pi_i^{-1}(A))$. Note $\pi_i^{-1}(A)\in\mathcal{C}_\Sigma$ since $\pi_i$ is continuous, so it follows that $(X_i^n)^{-1}(A)\in\mathcal{F}$. Thus $X_i^n$ is a $C(\Lambda)$-valued random variable.
		
		Suppose the sequence $(\mathcal{L}^n)$ is tight. Then $(\mathcal{L}^n)$ is relatively compact, that is, every subsequence $(\mathcal{L}^{n_k})$ has a further subsequence $(\mathcal{L}^{n_{k_\ell}})$ converging weakly to some $\mathcal{L}$. Then for each $i\in\Sigma$, since $\pi_i$ is continuous, the subsequence $(\pi_i(\mathcal{L}^{n_{k_\ell}}))$ of $(\pi_i(\mathcal{L}^{n_k}))$ converges weakly to $\pi_i(\mathcal{L})$ by the continuous mapping theorem. Thus every subsequence of $(\pi_i(\mathcal{L}^n))$ has a convergent subsequence. Since $C(\Lambda)$ is a Polish space by the argument in problem 1, Prohorov's theorem implies that each $(\pi_i(\mathcal{L}^n))$ is tight.
		
		Conversely, suppose $(\pi_i(\mathcal{L}^n))$ is tight for all $i\in\Sigma$. Then for each $i$, every subsequence $(\pi_i(\mathcal{L}^{n_k}))$ has a further subsequence $(\pi_i(\mathcal{L}^{n_{k_\ell}})$ converging weakly to some $\mathcal{L}_i$. By diagonalizing the subsequences $(n_{k_\ell})$, we obtain a sequence that works for all $i$, so that $\pi_i(\mathcal{L}^{n_{k_\ell}})\implies \mathcal{L}_i$ for all $i$ simultaneously. If $Q^n$ is the law of $\mathcal{L}^n$ as above and $Q_i$ is the law of $\mathcal{L}_i$, we claim that $Q^{n_{k_\ell}}$ converges weakly to the product measure $Q_1 \otimes Q_2 \otimes \cdots$.
		
		Since $C(\Sigma\times\Lambda)$ is homeomorphic to $\prod_{i\in\Sigma} C(\Lambda)$, we can identify the sequence of random variables $(\mathcal{L}_i)_{i\in\Sigma}$ with an element of $C(\Sigma\times\Lambda)$. Then $\mathcal{L}^{n_{k_\ell}}\implies (\mathcal{L}_i)_{i\in\Sigma}$.
	
	\subsection*{Problem 9}


\section{Lozenge tilings of the hexagon}

	\subsection*{Problem 10}
	
	\subsection*{Problem 11}

\end{document}