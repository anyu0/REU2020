%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
% Appendix
%
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

\section{Appendix}\label{Appendix1}

\subsection{Proof of Lemma \ref{Polish}}

Without loss of generality, we use the following compact exhaustion of $\Sigma\times\Lambda$. Define the sets
\[
K_n := \Sigma_n \times \Lambda_n := \Sigma_n \times [a_n,b_n]
\]
as follows. We take $\Sigma_n$ to be the set of the $n$ smallest elements of $\Sigma$, or all of $\Sigma$ if $n\geq \#(\Sigma)$. If $a\in\Lambda$, i.e, $\Lambda$ is closed at the left, then $a_n=a$ for all $n$, and likewise $b_n=b$ if $b\in\Lambda$. If $a\notin\Lambda$, we let $a_n\in\Lambda$, $a_n>a$ be a sequence decreasing to $a$, for instance $a_n=a+\frac{1}{n}$ if $a>-\infty$, or $a_n=-n$ if $a_n=-\infty$. If $b\notin\Lambda$, we let $b_n\in\Lambda, b_n\nearrow b$. In any case, we see that the sets $K_1\subset K_2\subset\cdots\subset\Sigma\times\Lambda$ are compact, they cover $\Sigma\times\Lambda$, and any compact subset $K$ of $\Sigma\times\Lambda$ is contained in all $K_n$ for sufficiently large $n$.

We now define, for each $n$ and $f,g\in C(\Sigma\times\Lambda)$,
\[
d_n(f,g) := \sup_{(i,t)\in K_n} |f(i,t)-g(i,t)|,\quad d_n'(f,g) := \min\{d_n(f,g), 1\} 
\]
Clearly each $d_n$ is nonnegative and satisfies the triangle inequality, and it is then easy to see that the same properties hold for $d_n'$. Furthermore, $d_n'\leq 1$, so the function
\[
d(f,g) := \sum_{n=1}^\infty 2^{-n} d_n'(f,g)
\]
in the statement of the lemma is well-defined. We first observe that $d$ is a metric on $C(\Sigma\times\Lambda)$. Indeed, it is nonnegative, and if $f=g$, then each $d_n'(f,g)=0$, so the sum is 0. Conversely, if $f\neq g$, then since the $K_n$ cover $\Sigma\times\Lambda$, we can choose $n$ large enough so that $K_n$ contains an $x$ with $f(x)\neq g(x)$. Then $d_n'(f,g)\neq 0$, and hence $d(f,g)\neq 0$. The triangle inequality holds for $d$ since it holds for each $d_n'$.

Now we prove that the topology $\tau_d$ on $C(\Sigma\times\Lambda)$ induced by $d$ is the same as the topology of uniform convergence over compacts, which we will denote $\tau_c$. Recall that $\tau_c$ is generated by the basis consisting of sets
\[
B_K(f,\epsilon) = \Big\{g\in C(\Sigma\times\Lambda) : \sup_{(i,t)\in K} |f(i,t) - g(i,t)| < \epsilon \Big\},
\]
for $K\subset\Sigma\times\Lambda$ compact, $f\in C(\Sigma\times\Lambda)$, and $\epsilon>0$. First, choose $\epsilon>0$ and $f\in C(\Sigma\times\Lambda)$. Let $g\in B^d_\epsilon(f)$, i.e., $d(f,g)<\epsilon$. We will find a set $A_g\in\tau_c$ such that $g\in A_g\subset B^d_\epsilon(f)$. Let $\delta := d(f,g)$, and choose $n$ large enough so that $\sum_{k>n} 2^{-k} < \frac{\epsilon-\delta}{2}$. Define $A_g := B_{K_n}(g,\frac{\epsilon-\delta}{n})$, and suppose $h\in A_g$. Then since $K_m\subseteq K_n$ for $m\leq n$, we have
\begin{align*}
d(f,h) &\leq d(f,g) + d(g,h) \leq \delta + \sum_{k=1}^n 2^{-k}d_n(g,h) + \sum_{k>n} 2^{-k} \leq \delta + \frac{\epsilon-\delta}{2} + \frac{\epsilon-\delta}{2} = \epsilon.
\end{align*}
Therefore $g\in A_g\subset B^d_\epsilon(f)$. It follows that $B^d_\epsilon(f)\in \tau_c$. Indeed, we can write
\[
B^d_\epsilon(f) = \bigcup_{g\in B^d_\epsilon(f)} A_g,
\]
a union of elements of $\tau_c$. This proves that $\tau_d\subseteq\tau_c$.

To prove the converse, let $K\subset\Sigma\times\Lambda$ be compact, $f\in C(\Sigma\times\Lambda)$, and $\epsilon>0$. Choose $n$ so that $K\subset K_n$, and let $g\in B_K(f,\epsilon)$ and $\delta:= \sup_{x\in K} |f(x)-g(x)|$. If $d(g,h) < 2^{-n}(\epsilon-\delta)$, then $d_n'(g,h) \leq 2^n d(g,h) < \epsilon-\delta$, hence $d_n(g,h) < \epsilon-\delta$. It follows that
\begin{align*}
\sup_{x\in K} |f(x)-h(x)| &\leq \delta + \sup_{x\in K} |g(x)-h(x)| \leq \delta + d_n(g,h) \leq \delta + \epsilon-\delta = \epsilon.
\end{align*}
Thus $g\in B^d_{2^{-n}(\epsilon-\delta)}(f) \subset B_K(f,\epsilon)$. Therefore $\tau_c\subseteq \tau_d$, and we conclude that $\tau_d = \tau_c$.

Next, we show that $(C(\Sigma\times\Lambda), d)$ is a complete metric space. Let $(f_n)_{n\geq 1}$ be Cauchy with respect to $d$. Then we claim that $(f_n)$ must be Cauchy with respect to $d_n'$, on each $K_n$. Indeed, $d(f_\ell, f_m) \geq 2^{-n}d_n'(f_\ell, f_m)$, so if $(f_n)$ were not Cauchy with respect to $d_n'$, it would not be Cauchy with respect to $d$ either. Thus $(f_n)$ is uniformly Cauchy on each $K_n$, and hence converges uniformly to a limit $f^{K_n}$ on each $K_n$. Since the limit must be unique at each point of $\Sigma\times\Lambda$, we have $f^{K_n}(x) = f^{K_m}(x)$ if $x\in K_n\cap K_m$. Since $\bigcup K_n = \Sigma\times\Lambda$, we obtain a well-defined function $f$ on all of $\Sigma\times\Lambda$ given by $f(x)=\lim_{n\to\infty} f^{K_n}(x)$. Given any compact $K\subset \Sigma\times\Lambda$, if $n$ is large enough so that $K\subset K_n$, then because $f_n \to f^{K_n} = f|_{K_n}$ uniformly on $K_n$, we have $f_n \to f^{K_n}|_K = f|_K$ uniformly on $K$. That is, for any $K\subset\Sigma\times\Lambda$ compact and $\epsilon>0$, we have $f_n \in B_K(f,\epsilon)$ for all sufficiently large $n$. Therefore $(f_n)$ converges to $f$ in $\tau_c$, and equivalently in the metric $d$.

Lastly, we prove separability, c.f. \cite[Example 1.3]{Billing}. For each pair of positive integers $n,k$, let $D_{n,k}$ be the subcollection of $C(\Sigma\times\Lambda)$ consisting of polygonal functions that are piecewise linear on $\{j\}\times I_{n,k,i}$ for each $j\in\Sigma_n$ and each subinterval 
\[
I_{n,k,i} := \big[a_n+\tfrac{i-1}{k}(b_n-a_n), a_n+\tfrac{i}{k}(b_n-a_n)\big], \quad 1\leq i\leq k,
\] 
taking rational values at the endpoints of these subintervals, and extended linearly to all of $\Lambda = [a,b]$. Then $D := \bigcup_{n,k} D_{n,k}$ is countable, and we claim that it is dense in $\tau_c$. To see this, let $K\subset\Sigma\times\Lambda$ be compact, $f\in C(\Sigma\times\Lambda)$, and $\epsilon>0$, and choose $n$ so that $K\subset K_n$. Since $f$ is uniformly continuous on $K_n$, we can choose $k$ large enough so that for $0\leq i\leq k$, if $t\in I_{n,k,i}$, then $|f(j,t) - f(j, a_n + \frac{i}{k}(b_n-a_n))| < \epsilon/2$ for all $j\in\Sigma_n$. We then choose $g\in \bigcup_k D_{n,k}$ with $|g(j,a_n + \frac{i}{k}(b_n-a_n)) - f(j,a_n + \frac{i}{k}(b_n-a_n))| < \epsilon/2$. Then $f(j,t)$ is within $\epsilon$ of both $g(j,a_n + \frac{i-1}{k}(b_n-a_n))$ and $g(j,a_n + \frac{i}{k}(b_n-a_n))$. Since $g(j,t)$ lies between these two values, $f(j,t)$ is with $\epsilon$ of $g(j,t)$ as well. In summary,
\[
\sup_{(j,t)\in K} |f(j,t)-g(j,t)| \leq \sup_{(j,t)\in K_n} |f(j,t)-g(j,t)| < \epsilon,
\] 
so $g\in B_K(f,\epsilon)$. This proves that $D$ is a countable dense subset of $C(\Sigma\times\Lambda)$.


\subsection{Proof of Lemma \ref{2Tight}}

We first state and prove two auxiliary results regarding the topology of uniform convergence over compacts. The first lemma states that a $C(\Sigma\times\Lambda)$-valued random variable is determined by its finite-dimensional distributions.

\begin{lemma}\label{FDD}
	Let $(\Omega,\mathcal{F},\pr)$ be a probability space and $X,Y$ random variables on $(\Omega,\mathcal{F},\pr)$ taking values in $C(\Sigma\times\Lambda)$. Suppose that for all $n\in\mathbb{N}$, $(i_1,t_1),\dots,(i_n,t_n)\in\Sigma\times\Lambda$, and $x_1,\dots,x_n\in\mathbb{R}$, we have that
	\begin{align*}
	&\mathbb{P}\left(X(i_1,t_1)\leq x_1,\dots,X(i_n,t_n)\leq x_n\right) = \mathbb{P}\left(Y(i_1,t_1)\leq x_1,\dots,Y(i_n,t_n)\leq x_n\right).
	\end{align*}
	Then $X$ and $Y$ are equal in distribution, i.e., $\mathbb{P}(X\in A) = \mathbb{P}(Y\in A)$ for all $A\in\mathcal{C}_\Sigma$.
	
\end{lemma}

\begin{proof}
	
	Let $\mathcal{S}$ denote the collection of cylinder sets
	\[
	\{f\in C(\Sigma\times\Lambda) : f(i_1,t_1)\in A_1, \dots, f(i_n,t_n) \in A_n\}, \quad A_1,\dots,A_n\in\mathcal{B}(\mathbb{R}). 
	\]
	Since the Borel sets in $\mathbb{R}$ are generated by intervals of the form $(-\infty,x]$, the hypothesis is equivalent to requiring that the probability measures $\mathbb{P}\circ X^{-1}$ and $\mathbb{P}\circ Y^{-1}$ agree on $\mathcal{S}$. We will show that $\mathcal{S}$ is a $\pi$-system generating $\mathcal{C}_\Sigma$, which will imply by [] that $\mathbb{P}\circ X^{-1} = \mathbb{P}\circ Y^{-1}$ on all of $\mathcal{C}_\Sigma$. Observe that the intersection of two elements of $\mathcal{S}$ is clearly another element of $\mathcal{S}$, so $\mathcal{S}$ is a $\pi$-system. 
	
	We claim that the set $\{f\in C(\Sigma\times\Lambda):f(i_k,t_k)\leq x_k\}$ is closed in the topology of compact convergence. If $f_n(i_k,t_k)\leq x_k$ for all $n$ and $f_n\to f$ in the topology of compact convergence, then by taking limits on a compact set containing $(i_k,t_k)$, we find $f(i_k,t_k)\leq x_k$ as well. This proves that $\sigma(\mathcal{S})\subseteq\mathcal{C}_\Sigma$. 
	
	To prove the opposite inclusion, let $K\subset\Sigma\times\Lambda$ be compact, $f\in C(\Sigma\times\Lambda)$, and $\epsilon>0$, and let $H$ be a countable dense subset of $K$. (Recall that every compact metric space is separable, and $K$ is homeomorphic to a product of finitely many compact sets in $\mathbb{R}$, which are metrizable. So $K$ is separable.) We claim that
	\[
	B_K(f,\epsilon) = \bigcup_{n=1}^\infty\,\bigcap_{(i,t)\in H} \{g\in C(\Sigma\times\Lambda) : g(i,t) \in  (f(i,t)-(1-2^{-n})\epsilon, f(i,t) + (1-2^{n})\epsilon)\}.
	\]
	Indeed, if $g\in B_K(f,\epsilon)$, i.e., $\sup_{(i,t)\in K} |g(i,t)-f(i,t)| < \epsilon$. Then since $1-2^{-n}\nearrow 1$, we can choose $n$ large enough so that 
	\[
	|g(i,t)-f(i,t)| < (1-2^{-n})\epsilon
	\] 
	for all $(i,t)\in K$ (in particular with $(i,t)\in H$). Conversely, suppose $g$ is in the set on the right. Then since $g$ is continuous and $H$ is dense in $K$, we find that for some $n\geq 1$,
	\[
	|g(i,t)-f(i,t)| \leq (1-2^{-n})\epsilon < \epsilon
	\]
	for all $(i,t)\in K$. Hence $g\in B_K(f,\epsilon)$. This proves the claim. Since $H$ is countable, $B_K(f,\epsilon)$ is formed from countably many unions and intersections of sets in $\mathcal{S}$, thus $B_K(f,\epsilon)\in\sigma(\mathcal{S})$.
	
	Now by Lemma \ref{Polish}, the topology generated by the basis $\mathcal{A} = \{B_K(f,\epsilon)\}$ is separable and metrizable. The balls of rational radii centered at points of a countable dense subset then give a countable basis $\mathcal{B}$ for the same topology. We claim that this implies that every open set is a \textit{countable} union of sets $B_K(f,\epsilon)$. To see this, let $B\in\mathcal{B}$, and write $B=\bigcup_{\alpha\in I} A_\alpha$, for sets $A_\alpha\in\mathcal{A}$. Then for each $x\in B$, pick $\alpha_x \in I$ such that $x\in A_{\alpha_x}$. Since $\mathcal{B}$ is a basis, there is a set $B_x \in \mathcal{B}$ with $x\in B_x\subseteq A_{\alpha_x}$. Then $B = \bigcup_{x\in B} A_{\alpha_x}$. Note that if $y\in B_y \subseteq A_{\alpha_y}$ and $B_y=B_x$, then in fact $y\in A_{\alpha_x}$, so we can remove $A_{\alpha_y}$ from the union. In other words, we can choose the $A_{\alpha_x}$ so that each corresponds to exactly one $B_x$. But there are only countably many distinct sets $B_x$, so we see that $B$ is a countable union of elements of $\mathcal{A}$. Since every open set can be written as a countable union of elements of $B$, this proves the claim. Since $\mathcal{A}\subseteq\sigma(\mathcal{S})$ by the above, it follows that every open set is in $\sigma(\mathcal{S})$, and consequently so is every Borel set, i.e., $\mathcal{C}_\Sigma \subseteq \sigma(\mathcal{S})$. This completes the proof
	
\end{proof}

The next result shows that a sequence of line ensembles is tight if and only if all individual curves form tight sequences.

\begin{lemma}\label{ProjTight}
	Consider the projection maps $\pi_i: C (\Sigma \times \Lambda) \rightarrow C(\Lambda)$, $i \in \Sigma$, given by
	$\pi_i(F)(x) = F(i, x) \mbox{ for $x \in \Lambda$}.$ Then the $\pi_i$ are continuous. Suppose that $(\mathcal{L}^n)_{n\geq 1}$ is a sequence of $\Sigma$-indexed line ensembles on $\Lambda$. Then $(\mathcal{L}^n)$ is tight if and only if for each $i \in \Sigma$ the sequence $(X_i^n)_{n\geq 1}$ is tight.
	
\end{lemma}

\begin{proof}
	
Since $C(X)$ with the topology of uniform convergence on compacts is metrizable by Lemma \ref{Polish}, to show that the $\pi_i$ are continuous, it suffices to show that if $f_n\to f$ in $C(\Sigma\times\Lambda)$, then $\pi_i(f_n)\to \pi_i(f)$ in $C(\Lambda)$. But this is immediate, since if $f_n\to f$ uniformly on compact subsets of $\Sigma\times\Lambda$, then in particular $f_n(i,\cdot)\to f(i,\cdot)$ uniformly on compact subsets of $\Lambda$. Now write $X_i^n := \pi_i(\mathcal{L}^n)$. If $A$ is a Borel set in $C(\Lambda)$, then $(X_i^n)^{-1}(A) = (\mathcal{L}^n)^{-1}(\pi_i^{-1}(A))$. Note $\pi_i^{-1}(A)\in\mathcal{C}_\Sigma$ since $\pi_i$ is continuous, so it follows that $(X_i^n)^{-1}(A)\in\mathcal{F}$. Thus $X_i^n$ is a $C(\Lambda)$-valued random variable.

Suppose the sequence $(\mathcal{L}^n)$ is tight. By Lemma \ref{Polish}, $C(\Sigma\times\Lambda)$ is a Polish space, so it follows from Prohorov's theorem \cite[Theorem 5.1]{Billing}, that $(\mathcal{L}^n)$ is relatively compact. That is, every subsequence $(\mathcal{L}^{n_k})$ has a further subsequence $(\mathcal{L}^{n_{k_\ell}})$ converging weakly to some $\mathcal{L}$. Then for each $i\in\Sigma$, since $\pi_i$ is continuous, the subsequence $(\pi_i(\mathcal{L}^{n_{k_\ell}}))$ of $(\pi_i(\mathcal{L}^{n_k}))$ converges weakly to $\pi_i(\mathcal{L})$ by the continuous mapping theorem. Thus every subsequence of $(\pi_i(\mathcal{L}^n))$ has a convergent subsequence. Since $C(\Lambda)$ is a Polish space by the same argument as in the proof of Lemma \ref{Polish}, Prohorov's theorem implies that each $(\pi_i(\mathcal{L}^n))$ is tight.

Conversely, suppose $(\pi_i(\mathcal{L}^n))$ is tight for all $i\in\Sigma$. Then for each $i$, every subsequence $(\pi_i(\mathcal{L}^{n_k}))$ has a further subsequence $(\pi_i(\mathcal{L}^{n_{k_\ell}}))$ converging weakly to some $\mathcal{L}_i$. By diagonalizing the subsequences $(n_{k_\ell})$, we obtain a sequence that works for all $i$, so that $\pi_i(\mathcal{L}^{n_{k_\ell}})\implies \mathcal{L}_i$ for all $i$ simultaneously. Note that $C(\Sigma\times\Lambda)$ is homeomorphic to $\prod_{i\in\Sigma} C(\Lambda)$ with the product topology, with $f\in C(\Sigma\times\Lambda)$ identified with $(\pi_i(f))_{i\in\Sigma}$. It is not hard to see this by observing that the compact subsets $K$ of $\Sigma\times\Lambda$ are of the form $S\times I$, for $S$ finite and $I$ compact. Thus the homeomorphism identifies the basis elements $B_K(f,\epsilon)$ in $C(\Sigma\times\Lambda)$ with products of open sets $U_i$ in $C(\Lambda)$, such that if $i\notin S$ then simply $U_i = C(\Lambda)$; since $S$ is finite, these products $\prod_i U_i$ are basis elements of the product topology.

Consequently, we can identify the sequence of random variables $\mathcal{L} = (\mathcal{L}_i)_{i\in\Sigma}$ with an element of $C(\Sigma\times\Lambda)$. We argue that $\mathcal{L}^{n_{k_\ell}}\implies \mathcal{L}$. Let $U$ be a basis element in the product topology, i.e., $U = \prod_{i\in\Sigma} U_i$, with each $U_i$ open in $C(\Lambda)$ and all but finitely many $U_i = C(\Lambda)$. Without loss of generality, assume these finitely many $U_i\neq C(\Lambda)$ are $U_1,\dots,U_m$. Then
\[
\mathbb{P}(X \in U) = \mathbb{P}(\pi_1(X) \in U_1, \dots, \pi_m(X) \in U_m) = \prod_{i=1}^m \mathbb{P}(\pi_i(X)\in U_i).
\]
Therefore, since $\pi_i(\mathcal{L}^{n_{k_\ell}}) \implies \mathcal{L}_i$ for each $i$, we have by the portmanteau theorem, \cite[Theorem 2.1]{Billing}, that
\begin{align*}
\liminf_{\ell\to\infty} \mathbb{P}(\mathcal{L}^{n_{k_\ell}} \in U) &\geq \prod_{i=1}^m \liminf_{\ell\to\infty} \mathbb{P}(\pi_i(\mathcal{L}^{n_{k_\ell}})\in U_i) \geq \prod_{i=1}^m \mathbb{P}(\mathcal{L}_i \in U_i) = \mathbb{P}(\mathcal{L}\in U).
\end{align*}
Now by the same argument as in the proof of Lemma \ref{FDD}, every open set in $C(\Sigma\times\Lambda)$ is a countable union of sets of the form of $U$. Therefore by countable additivity, the inequalities above hold if $U$ is replaced by an arbitrary open set. Thus again by the portmanteau theorem, $\mathcal{L}^{n_{k_\ell}} \implies \mathcal{L}$ as desired. Hence $(\mathcal{L}^n)$ is relatively compact, and it follows from Prohorov's theorem  once again that $(\mathcal{L}^n)$ is tight.

\end{proof}

We are now ready to prove Lemma \ref{2Tight}.

\begin{proof}
	
By \cite[Theorem 7.3]{Billing}, a sequence $(P_n)$ of probability measures on $C[0,1]$ with the uniform topology is tight if and only if the following conditions hold:
\begin{align*}
\lim_{a\to\infty} \limsup_{n\to\infty} P_n(|x(0)|\geq a) &= 0, \\
\lim_{\delta\to 0} \limsup_{n\to\infty} P_n\Big(\sup_{|s-t|\leq\delta} |x(s)-x(t)| \geq \epsilon\Big) &= 0 \quad \textrm{for all}\;\epsilon>0.
\end{align*}

By replacing $[0,1]$ with $[a_k,b_k]$ and 0 with $a_0$, we see that the hypotheses in the lemma imply that the restricted sequences $(\mathcal{L}^n_i|_{[a_k,b_k]})_n$ are tight, hence relatively compact in the uniform topology on $C[a_k,b_k]$ by Prohorov's theorem, for every $i\in\Sigma$ and $k\geq 1$. Thus every subsequence $(\mathcal{L}^{n_m}_i|_{[a_k,b_k]})_m$ has a further subsequence $(\mathcal{L}^{n_{m_\ell}}_i|_{[a_k,b_k]})_\ell$ converging weakly to some $\mathcal{L}_i^{[a_k,b_k]}$. We claim that we can patch these $\mathcal{L}_i^{[a_k,b_k]}$ together to obtain a well-defined random variable $\mathcal{L}_i$ on all of $C(\Lambda)$, such that $\mathcal{L}_i|_{[a_k,b_k]} = \mathcal{L}_i^{[a_k,b_k]}$ for every $k$. By Lemma \ref{FDD}, it suffices to construct the finite-dimensional distributions of this $\mathcal{L}_i$. Given any finite collection $A=\{x_1,\dots,x_j\}$ of points in $\Lambda$, if we take $k$ large enough so that $A \subset [a_k,b_k]$, then the corresponding finite-dimensional distribution $\{\mathcal{L}_i(x_1)\in B_1, \dots, \mathcal{L}_i(x_j) \in B_j\}$ is determined by that of $\mathcal{L}_i^{[a_k,b_k]}$. Moreover, uniqueness of weak limits in distribution implies that this finite-dimensional distribution agrees with that of $\mathcal{L}_i^{[a_\ell,b_\ell]}$ whenever $A\subset[a_\ell,b_\ell]$. Thus we have specified well-defined finite-dimensional distributions for $\mathcal{L}_i$, which determines $\mathcal{L}_i$ on all of $C(\Lambda)$ by Lemma \ref{FDD}. By construction, the restriction of $\mathcal{L}_i$ to any $[a_k,b_k]$ is equal to $\mathcal{L}_i^{[a_k,b_k]}$ in distribution.

In particular, we see that $\mathcal{L}_i^{n_{m_\ell}}|_{[a_k,b_k]} \implies \mathcal{L}_i|_{[a_k,b_k]}$ in the uniform topology on $C[a_k,b_k]$, for every $k$. If $K\subset\Lambda$ is any compact set, then by taking $k$ large enough so that $K\subset [a_k,b_k]$, we also find $\mathcal{L}_i^{n_{m_\ell}}|_K \implies \mathcal{L}_i|_K$ in the uniform topology on $C(K)$. Let $B_K(f,\epsilon)$ be a basis element in $C(\Lambda)$, and let $B_\epsilon(f|_K)$ denote the corresponding ball in the uniform topology on $C(K)$. Then
\begin{align*}
\liminf_{\ell\to\infty}\,\mathbb{P}(\mathcal{L}^{n_{m_\ell}}_i \in B_K(f,\epsilon)) &= \liminf_{\ell\to\infty}\,\mathbb{P}(\mathcal{L}^{n_{m_\ell}}_i|_K \in B_\epsilon(f|_K))\\
&\geq \mathbb{P}(\mathcal{L}_i|_K \in B_\epsilon(f|_K)) = \mathbb{P}(\mathcal{L}_i \in B_K(f,\epsilon)).
\end{align*}
The inequality follows from weak convergence in the uniform topology on $C(K)$ and the portmanteau theorem. Since every open set in $C(\Lambda)$ can be written as a countable union of sets $B_K(f,\epsilon)$ (by the same argument as in the proof of Lemma \ref{FDD}), it follows from countable additivity that
\[
\liminf_{\ell\to\infty}\,\mathbb{P}(\mathcal{L}^{n_{m_\ell}}_i \in U) \geq \mathbb{P}(\mathcal{L}_i \in U)
\]
for any $U$ open in $C(\Lambda)$. Therefore $(\mathcal{L}_i^{n_{m_\ell}})_\ell$ converges weakly to $\mathcal{L}_i$, proving that $(\mathcal{L}^n_i)_n$ is relatively compact, hence tight by Prohorov's theorem, for every $i\in\Sigma$. We conclude that $(\mathcal{L}^n)$ is tight by Lemma \ref{ProjTight}.

\end{proof}


\subsection{Proof of Lemmas \ref{MCLxy} and \ref{MCLfg}}

We will prove the following lemma, of which the two lemmas are immediate consequences. In particular, Lemma \ref{MCLxy} is the special case when $g^b = g^t$, and Lemma \ref{MCLfg} is the case when $\vec{x} = \vec{x}\,'$ and $\vec{y} = \vec{y}\,'$. We argue in analogy to Lemma 5.6 in Dimitrov-Matestki.

\begin{lemma}
	Fix $k \in \mathbb{N}$, $T_0, T_1 \in \mathbb{Z}$ with $T_0 < T_1$, and two functions $g^b, g^t: \llbracket T_0, T_1 \rrbracket  \rightarrow [-\infty, \infty)$ with $g^b\leq g^t$. Also fix $\vec{x}, \vec{y}, \vec{x}\,', \vec{y}\,' \in \mathfrak{W}_k$, such that $g^b(T_0)\leq x_i$, $g^b(T_1)\leq y_i$, $g^t(T_0)\leq x_i'$, $g^t(T_1)\leq y_i'$, and $x_i\leq x_i'$, $y_i\leq y_i'$ for $1\leq i\leq k$. Assume that $\Omega_{avoid}(T_0, T_1, \vec{x}, \vec{y}, \infty,g^b)$ and $\Omega_{avoid}(T_0, T_1, \vec{x}\,', \vec{y}\,', \infty,g^t)$ are both non-empty. Then there exists a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, which supports two $\llbracket 1, k \rrbracket$-indexed Bernoulli line ensembles $\mathfrak{L}^t$ and $\mathfrak{L}^b$ on $\llbracket T_0, T_1 \rrbracket$ such that the law of $\mathfrak{L}^{t}$ {\big (}resp. $\mathfrak{L}^b${\big )} under $\mathbb{P}$ is given by $\mathbb{P}_{avoid, Ber}^{T_0, T_1, \vec{x}\,', \vec{y}\,', \infty, g^t}$ {\big (}resp. $\mathbb{P}_{avoid, Ber}^{T_0, T_1, \vec{x}, \vec{y}, \infty, g^b}${\big )} and such that $\mathbb{P}$-almost surely we have $\mathfrak{L}_i^t(r) \geq \mathfrak{L}^b_i(r)$ for all $i = 1,\dots, k$ and $r \in \llbracket T_0, T_1 \rrbracket$.
\end{lemma}

\begin{proof} We split the proof into two steps.\\
	
	\noindent\textbf{Step 1.} We first aim to construct a Markov chain $(X^n,Y^n)_{n\geq 0}$, with \\$X^n\in \Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)$, $Y^n\in \Omega_{avoid}(T_0,T_1,\vec{x}\,',\vec{y}\,',\infty,g^t)$, with initial distribution given by the maximal paths
	\begin{align*}
	& X^0_1(t)=(x_1+t-T_0) \wedge y_1,\quad && Y^0_1(t)=(x_1'+t-T_0) \wedge y_1'\\
	& X^0_k(t)=(x_k+t-T_0) \wedge y_k \wedge X^0_{k-1}(t), \quad && Y^0_k(t)=(x_k'+t-T_0) \wedge y_k' \wedge Y^0_{k-1}(t).
	\end{align*}
	for $t\in\llbracket T_0, T_1\rrbracket$. We want this chain to have the following properties: 
	\begin{enumerate}[label=(\arabic*)]
		
		\item $(X^n)_{n\geq 0}$ and $(Y^n)_{n\geq 0}$ are both Markov in their own filtrations,
		
		\item $(X^n)$ is irreducible and has as an invariant distribution the uniform measure $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x},\vec{y},\infty,g^b}$,
		
		\item $(Y^n)$ is irreducible and has invariant distribution $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x}',\vec{y}',\infty,g^t}$,
		
		\item $X^n_i\leq Y^n_i$ on $\llbracket T_0, T_1\rrbracket$ for all $n\geq 0$ and $1\leq i \leq k$.
		
	\end{enumerate}
	
	\noindent This will allow us to conclude convergence of $X^n$ and $Y^n$ to these two uniform measures.
	
	We specify the dynamics of $(X^n, Y^n)$ as follows. At time $n$, we uniformly sample a segment $\{t\}\times[z, z+1]$, with $t\in\llbracket T_0, T_1\rrbracket$ and $z\in\llbracket x_k,y_1'-1\rrbracket$. We also flip a fair coin, with $\mathbb{P}(\textrm{heads})=\mathbb{P}(\textrm{tails})=1/2$. We update $X^n$ and $Y^n$ using the following procedure. For all points $s\neq t$, we set $X^{n+1}(s) = X^n(s)$. If $T_0 < t < T_1$ and $X^n_i(t-1)=z$ and $X^n_i(t+1)=z+1$ (note that this implies $X^n_i(t)\in\{z,z+1\}$), then we set
	\[
	X^{n+1}_i(t) = \begin{cases}
	z+1, & \textrm{if heads},\\
	z, & \textrm{if tails},
	\end{cases}
	\]
	assuming that this move does not cause $X^{n+1}_i(t)$ to fall below $g^b(t)$. In all other cases, we leave $X^{n+1}_i(t)=X^n_i(t)$. We update $Y^n$ using the same rule, with $g^t$ in place of $g^b$. [Maybe add a figure here.] We will verify below in the proof of (4) that $X^n$ and $Y^n$ are in fact non-intersecting for all $n$, but we assume this for now.
	
	It is easy to see that $(X^n,Y^n)$ is a Markov chain, since at each time $n$, the value of $(X^{n+1},Y^{n+1})$ depends only on the current state $(X^n,Y^n)$, and not on the time $n$ or any of the states prior to time $n$. Moreover, the value of $X^{n+1}$ depends only on the state $X^n$, not on $Y^n$, so $(X^n)$ is a Markov chain in its own filtration. The same applies to $(Y^n)$. This proves the property (1) above.
	
	We now argue that $(X^n)$ is each irreducible. Observe that the initial distribution $X^0$ is by construction maximal, in the sense that for any $Z\in \Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)$, we have $Z_i \leq X^0_i$ for all $i$. Thus to reach $Z$ from the initial state $X_0$, we only need to move the paths downward, and there is no danger of the paths $X_i$ crossing when we do so. We start by ensuring $X^n_k = Z_k$. We successively sample segments which touch $Z_k$ at each point in $\llbracket T_0,T_1\rrbracket$ where $Z_k$ differs from $X_k$, and choose the appropriate coin flips until the two agree on all of $\llbracket a,b\rrbracket$. We repeat this procedure for $X^n_i$ and $Z^i$, with $i$ descending. Since each of these samples and flips has positive probability, and this process terminates in finitely many steps, the probability of transitioning from $X^n$ to $Z$ after some number of steps is positive. The same reasoning applies to show that $(Y^n)$ is irreducible.
	
	To see that the uniform measure $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x},\vec{y},\infty,g^b}$ on $\Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)$ is invariant for $(X^n)$, fix any line ensemble $\omega\in\Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)$. For simplicity, write $\mu$ for the uniform measure and $N=|\Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)|$ for the (finite) number of allowable ensembles. Then for all ensembles $\tau\in\Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)$, $\mu(\tau) = 1/N$. Hence
	\begin{align*}
	& \sum_\tau \mu(\tau)\mathbb{P}(X^{n+1} = \omega\,|\,X^n = \tau) = \frac{1}{N}\sum_\tau \mathbb{P}(X^{n+1} = \omega\,|\,X^n = \tau)\\
	= \; & \frac{1}{N}\sum_\tau \mathbb{P}(X^{n+1} = \tau\,|\,X^n = \omega) = \frac{1}{N}\cdot 1 = \mu(\omega).
	\end{align*}
	The second equality is clear if $\tau=\omega$. Otherwise, note that $\mathbb{P}(X_{n+1} = \omega\,|\,X_n = \tau) \neq 0$ if and only if $\tau$ and $\omega$ differ only in one indexed path (say the $i$th) at one point $t$, where $|\tau_i(t)-\omega_i(t)|=1$, and this condition is also equivalent to $\mathbb{P}(X^{n+1} = \tau\,|\,X^n = \omega) \neq 0$. If $X^n=\tau$, there is exactly one choice of segment $\{t\}\times[z,z+1]$ and one coin flip which will ensure $X^{n+1}_i(t)=\omega(t)$, i.e., $X^{n+1}=\omega$. Conversely, if $X^n=\omega$, there is one segment and one coin flip which will ensure $X^{n+1}=\tau$. Since the segments are sampled uniformly and the coin flips are fair, these two conditional probabilities are in fact equal. This proves (2), and an analogous argument proves (3).
	
	Lastly, we argue that $X^n_i\leq Y^n_i$ for all $n\geq 0$ and $1\leq i\leq k$. The same argument will prove that $X^n_{i+1}\leq X^n_i$ for all $n,i$, so that $X^n$ is in fact non-intersecting for all $n$, and likewise for $Y^n$. This is of course true at $n=0$. Suppose it holds at some $n\geq 0$. Then since the update rule can only change the values of $X_i$ and $Y_i$ at a single point $t$, it suffices to look at the possible updates to the $i$th curve at a single point $t\in\llbracket T_0, T_1\rrbracket$. Notice that the update can only change values by at most 1, and if $Y^n_i(t) - X^n_i(t) = 1$, then the only way the ordering could be violated is if $Y_i$ were lowered and $X_i$ were raised at the next update. But this is impossible, since a coin flip of heads can only raise or leave fixed both curves, and tails can only lower or leave fixed both curves. Thus it suffices to assume $X^n_i(t) = Y^n_i(t)$. 
	
	There are two cases to consider that violate the ordering of $X^{n+1}_i(t)$ and $Y^{n+1}_i(t)$. Either (i) $X_i(t)$ is raised but $Y_i(t)$ is left fixed, or (ii) $Y_i(t)$ is lowered yet $X_i(t)$ is left fixed. These can only occur if the curves exhibit one of two specific shapes on $\llbracket t-1, t+1\rrbracket$. For $X_i(t)$ to be raised, we must have $X^n_i(t-1) = X^n_i(t) = X^n_i(t+1) - 1$, and for $Y_i(t)$ to be lowered, we must have $Y^n_i(t-1) - 1 = Y^n_i(t) = Y^n_i(t+1)$. From the assumptions that $X^n_i(t) = Y^n_i(t)$, and $X^n_i \leq Y^n_i$, we observe that both of these requirements force the other curve to exhibit the same shape on $\llbracket t-1, t+1\rrbracket$. Then the update rule will be the same for both curves, proving that both (i) and (ii) are impossible. \\
	
	\noindent\textbf{Step 2.} It follows from (2) and (3) and \cite[Theorem 1.8.3]{Norris} that $(X^n)_{n\geq 0}$ and $(Y^n)_{n\geq 0}$ converge weakly to $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x},\vec{y},\infty,g^b}$ and $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x}',\vec{y}',\infty,g^t}$ respectively. In particular, $(X^n)$ and $(Y^n)$ are tight, so $(X^n,Y^n)_{n\geq 0}$ is tight as well. By Prohorov's theorem, it follows that $(X^n,Y^n)$ is relatively compact. Let $(n_m)$ be a sequence such that $(X^{n_m},Y^{n_m})$ converges weakly. Then by the Skorohod representation theorem \cite[Theorem 6.7]{Billing}, it follows that there exists a probability space $(\Omega,\mathcal{F},\mathbb{P})$ supporting $C(\llbracket 1, k\rrbracket \times \llbracket T_0, T_1\rrbracket)$-valued random variables $\mathfrak{X}^n$, $\mathfrak{Y}^n$ and $\mathfrak{X},\mathfrak{Y}$ such that
	\begin{enumerate}[label=(\arabic*)]
		
		\item The law of $(\mathfrak{X}^n,\mathfrak{Y}^n)$ under $\mathbb{P}$ is the same as that of $(X^n,Y^n)$,
		
		\item $\mathfrak{X}^n(\omega) \longrightarrow \mathfrak{X}(\omega)$ for all $\omega\in\Omega$,
		
		\item $\mathfrak{Y}^n(\omega) \longrightarrow \mathfrak{Y}(\omega)$ for all $\omega\in\Omega$.
		
	\end{enumerate}
	
	In particular, (1) implies that $\mathfrak{X}^{n_m}$ has the same law as $X^{n_m}$, which converges weakly to $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x},\vec{y},\infty,g^b}$. It follows from (2) and the uniqueness of limits that $\mathfrak{X}$ has law $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x},\vec{y},\infty,g^b}$. Similarly, $\mathfrak{Y}$ has law $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x}',\vec{y}',\infty,g^t}$. Moreover, condition (4) in Step 1 implies that $\mathfrak{X}^n_i \leq \mathfrak{Y}^n_i$, $\mathbb{P}$-a.s., so $\mathfrak{X}_i \leq \mathfrak{Y}_i$ for $1\leq i\leq k$, $\mathbb{P}$-a.s. Thus we can take $\mathfrak{L}^b := \mathfrak{X}$ and $\mathfrak{L}^t := \mathfrak{Y}$.
	
\end{proof}

\subsection{Weak Convergence of Scaled avoiding Bernoulli Line Ensemble} We consider there $\{1,\dots,k\}$-indexed line ensembles with distribution given by $\mathbb{P}^{0,T,\vec{x},\vec{y},\infty,-\infty}_{avoid,Ber}$ in the sense of Definition \ref{DefAvoidingLawBer}. Recall that this is just the law of $k$ independent Bernoulli random walks that have been conditioned to start from $(x_{1},\dots,x_{k})$ at time $0$ and end at $(y_1,\cdots,y_{k})$ at time $T$ and are always ordered. Here $x_{1}\geq x_{2}\geq \cdots \geq x_{k}$, $y_{1}\geq y_{2}\geq \cdots \geq y_{k}$ and $x_{i}$, $y_{i}\in\mathbb{Z}$ satisfy $T\geq y_{i}-x_{i}\geq 0$ for $i=1,\dots,k$. We will drop the infinities and simply write $\mathbb{P}^{0,T,\vec{x},\vec{y}}_{avoid,Ber}$ for the measure.

Fix $p,t\in(0,1)$, $k\in\mathbb{N}$, $a_{i}$, $b_{i}\in\mathbb{R}$ for $i=1,\dots,k$ such that $a_{1}\geq \cdots \geq a_{k}$ and $b_{1}\geq \cdots \geq b_{k}$. Suppose that $\vec{x}^{T}=(x_{1}^{T},\cdots,x_{k}^{T})$ and $\vec{y}^{T}=(y_{1}^{T},\cdots,y_{k}^{T})$ is a sequence of $k$-dimensional vectors with integer entries such that $$\lim_{T\rightarrow\infty}\frac{x_{i}^{T}}{\sqrt{T}}=a_{i} \text{ and } \lim_{T\rightarrow\infty}\frac{y_{i}^{T}-pT}{\sqrt{T}}=b_{i}$$ for $i=1,\dots,k$. Define the sequence of random $k$-dimensional vectors $Z^{T}$ by $$Z^{T}=\big(\frac{L_{1}(tT)-ptT}{\sqrt{T}},\cdots,\frac{L_{k}(tT)-ptT}{\sqrt{T}}\big),$$ where $(L_{1},\cdots,L_{k})$ is $\mathbb{P}^{0,T,\vec{x},\vec{y}}_{avoid,Ber}$-distributed. We will prove the following results:
\begin{enumerate}
	\item The avoiding Bernoulli line ensemble at position $\lfloor tT \rfloor$ has the following distribution: $$\mathbb{P}(L_{1}(\lfloor tT \rfloor) = \lambda_{1}, \cdots, L_{k}(\lfloor tT \rfloor) = \lambda_{k})=\frac{s_{\lambda/\mu}(1^{\lfloor tT \rfloor})\cdot s_{\kappa/\lambda}(1^{T-\lfloor tT \rfloor})}{s_{\kappa/\mu}(1^{T})}$$ where $\lambda_{1}>\lambda_{2}>\cdots >\lambda_{k}$ are positive integers, $s_{\lambda/\mu}$ denote skew Schur polynomials and they are specialized in all parameters equal to $1$. The $\mu$ partition is just the vector $\vec{x}^{T}$ and the $\kappa$ partition should be $\vec{y}^{T}$.
	\item When $a_{1}> \cdots > a_{k}$ and $b_{1}> \cdots > b_{k}$ are all distinct, the random vector $Z^{T}$ converges weakly to a random vector with the density $$\rho(z_{1},\cdots,z_{k})=\frac{1}{Z}\cdot \det\big[e^{c_{1}(t,p)a_{i}z_{j}}\big]_{i,j=1}^{k}\det\big[e^{c_{2}(t,p)b_{i}z_{j}}\big]_{i,j=1}^{k}\prod_{i=1}^{k}e^{-c_{3}(t,p)z_{i}^{2}}\mathbbm{1}_{\{z_{1}>\cdots >z_{k}\}}$$ where $c_{1},c_{2},c_{3}$ are constants depending on $p,t$: 
	\begin{align*}
		&c_{1}(p,t)=\frac{1}{p(p+1)t}, \quad c_{2}(p,t)=\frac{1}{p(p+1)(1-t)}, \quad c_{3}(p,t)=\frac{1}{2p(p+1)t(1-t)}
	\end{align*}
	and $Z$ is a constant depending on $p,t,\vec{a},\vec{b}$ such that $\rho(z_{1},\cdots,z_{k})$ integrates to $1$ over $\mathbb{R}^{k}$.
	\item When $a_{1}\geq \cdots \geq a_{k}$ and $b_{1}\geq \cdots \geq b_{k}$ contain collided values, we suppose
	\begin{align*}
	&\vec{a}_{0}=(\underbrace{\alpha_{1},\cdots,\alpha_{1}}_{m_{1}},\cdots,\underbrace{\alpha_{p},\cdots,\alpha_{p}}_{m_{p}})\\
	&\vec{b}_{0}=(\underbrace{\beta_{1},\cdots,\beta_{1}}_{n_{1}},\cdots,\underbrace{\beta_{q},\cdots,\beta_{q}}_{n_{q}})
	\end{align*}
where $\alpha_{1}>\alpha_{2}>\cdots>\alpha_{p}$, $\beta_{1}>\beta_{2}>\cdots>\beta_{q}$ and $\sum_{i=1}^{p}m_{i}=\sum_{i=1}^{q}n_{i}=k$. Then, the random vector $Z^{T}$ converges weakly to a random vector, but with the density $$\rho_{\vec{a}_{0},\vec{b}_{0}}(z_{1},\cdots,z_{k})=\frac{1}{Z}\cdot \varphi(\vec{a}_{0},\vec{z},\vec{m})\psi(\vec{b}_{0},\vec{z},\vec{n})\prod_{i=1}^{k}e^{-c_{3}(t,p)z_{i}^{2}}\mathbbm{1}_{\{z_{1}>\cdots> z_{k}\}}$$ where $\vec{m}=(m_{1},\cdots,m_{k})$, $\vec{n}=(n_{1},\cdots,n_{k})$, $c_{1},c_{2},c_{3}$ are constants depending on $p,t$ as given in $(2)$, $Z$ is a constant depending on $p,t,\vec{a},\vec{b}$ such that $\rho_{\vec{a}_{0},\vec{b}_{0}}(z_{1},\cdots,z_{k})$ integrates to $1$ over $\mathbb{R}^{k}$, and $\varphi(\vec{a}_{0},\vec{z},\vec{m})$ and $\psi(\vec{b}_{0},\vec{z},\vec{n})$ are determinants:
\begin{equation*}
	\varphi(\vec{a}_{0},\vec{z},\vec{m})= \det
	\left[ \begin{array}{ccc}
		((c_{1}(t,p)z_{j})^{i-1}e^{c_{1}(t,p)\alpha_{1}z_{j}})_{\substack{i=1,\cdots,m_{1}\\j=1,\cdots,k}}\\
	\vdots\\
	((c_{2}(t,p)z_{j})^{i-1}e^{c_{1}(t,p)\alpha_{p}z_{j}})_{\substack{i=1,\cdots,m_{p} \\j=1,\cdots,k}}
	\end{array}
	\right]
\end{equation*}
\begin{equation*}
	\psi(\vec{b}_{0},\vec{z},\vec{n})= \det
	\left[ \begin{array}{ccc}
		((c_{2}(t,p)z_{j})^{i-1}e^{c_{2}(t,p)\beta_{1}z_{j}})_{\substack{i=1,\cdots,n_{1}\\j=1,\cdots,k}}\\
	\vdots\\
	((c_{2}(t,p)z_{j})^{i-1}e^{c_{2}(t,p)\beta_{q}z_{j}})_{\substack{i=1,\cdots, n_{q} \\j=1,\cdots,k}}
	\end{array}
	\right]
\end{equation*} 
\end{enumerate}
\begin{proof} Our proof is divided into $3$ parts corresponding to $3$ results, respectively.\\
\textbf{Part 1. }Let $\Omega(0,T,\vec{x}^T, \vec{y}^T)$ be the set of all non-intersecting Bernoulli line ensembles from $\vec{x}^T$ to $\vec{y}^T$. For each line ensemble $\mathfrak{B}\in \Omega(0,T,\bar x^T,\bar y^T)$ with $\mathfrak B=(B_1,...,B_k)$, we may define $\lambda_i(\mathfrak B):=(B_1(i),B_2(i),...,B_k(i))$, where $1 \leqslant i\leqslant T$ is an integer. The $\lambda_i$ form partitions since by the definition of avoiding Bernoulli line ensembles, we have the inequality $B_\alpha(i)>B_\beta(i)$ if $\alpha<\beta$. 
Now because $B_\alpha(i+1)-B_\alpha(i)\in \{0,1\}$ we know that $B_\alpha(i+1)\geq B_\alpha(i)$ but also since $B_\alpha(i+1)\in \mathbb{Z}$ and $B_{\alpha+1}(i+1)<B_\alpha(i+1)$ by the earlier stated inequality, we know that $B_{\alpha+1}(i+1)+1\leq B_\alpha(i+1)$ and so we find that 
\[B_{\alpha+1}(i+1)\leq B_\alpha(i)\leq B_\alpha(i+1)\]
We therefore find that for all $i$, $\lambda_i\preceq \lambda_{i+1}$. Note that when $i=0$, we get $\lambda_0=\bar x^T$ and $\lambda_T=\bar y^T$.

Now, let us define the set 
\[TB_{\kappa/\mu}^T:=\{(\lambda_0,...,\lambda_T)\mid \lambda_0=\mu, \lambda_T=\kappa, \lambda_i\preceq\lambda_{i+1}\}\] 
Now, if we take $f:\Omega(0,T,\bar x^T, \bar y ^T)\to TB_{\kappa/\mu}^T$ with $f(\mathfrak{B})= (\lambda_0(\mathfrak{B}),\cdots \lambda_T(\mathfrak{B}))$. We find that this function is in fact a bijection. 

First, to show for injectivity, suppose that there are two Bernoulli line ensembles, $\mathfrak{B}, \mathfrak{B}'\in \Omega(0,T,\bar x^T, \bar y ^T)$ such that $\mathfrak{B}\neq \mathfrak{B'}$.
Because Bernoulli line ensembles are determined by their values at integer times, we find that this would imply that there exists some $(q,r)$ such that $0\leq r\leq T$, $0\leq q \leq k$ and $B_q(r)\neq B'_q(r)$ where $B_q$ and $B_q'$ are components of $\mathfrak{B}$ and $\mathfrak{B'}$ respectively. 
This implies that $\lambda_r(\mathfrak B)\neq \lambda_r'(\mathfrak{B'})$, and we have injectivity. 

Now, surjectivity follows since for any $\bar\lambda=(\lambda_0,...,\lambda_T)$ we may define $\mathfrak{B}(\bar{\lambda})=(B_1(\bar\lambda),...,B_k(\bar\lambda))$ where $B_r(\bar\lambda)(i)=\lambda_i^r$ where $\lambda_i^r$ is the $i$\textit{th} entry of $\lambda_r$. The restrictions on $TB_{\kappa/\mu}^T$ ensure that each $\mathfrak{B}(\bar\lambda)\in \Omega(0,T,\bar x^T,\bar y^T)$, and so $f(\mathfrak B(\bar{\lambda}))=(\lambda_0,\cdots \lambda_T)$ by the definition $\mathfrak{B}(\bar\lambda)$. 

Applying the result regarding the relationship between number of partitions and skew Schur polynomial \cite[Chapter 1, (5.11)]{Mac}, we have \[s_{\kappa/\mu}(1^T)=\sum_{(\nu)}\prod_{i=1}^n s_{\nu^{(i)}/\nu^{i-1}}=\sum_{(\nu)} 1=\lvert TB_{\mu/\kappa}^T\rvert\]

Therefore, we can find that 
\begin{align*}
\pr(L_1(\lfloor tT\rfloor)=\lambda_1,\cdots, L_k(\lfloor tT\rfloor)=\lambda_k)
=&{}\frac{\lvert \Omega(0,\lfloor Tt\rfloor, \vec{x}^T, \lambda)\rvert\cdot \lvert \Omega(\lfloor Tt\rfloor ,T, \lambda, \vec{y}^T)\rvert}{\lvert \Omega(0, T, \vec{x}^T, \vec{y}^T)\rvert}\\
=&{}\frac{s_{\lambda/\vec{x}^T}(1^{\floor{Tt}})\cdot s_{\vec{y}^T/\lambda}(1^{T-\floor{Tt}})}{s_{\vec{y}^T/\vec{x}^T}(1^T)}
\end{align*} and proved the result.\\
\noindent \textbf{Part 2. }In the following, we prove the weak convergence of the random vector $Z^{T}$, when $\vec{a}$ and $\vec{b}$ consist of distinct entries. Let $\mathbb{W}_{k}^{o}$ denote the open Weyl chamber in $\mathbb{R}^{k}$:
$$\mathbb{W}_{k}^{o}=\{(x_{1},\cdots,x_{k})\in\mathbb{R}^{N}:x_{1}>x_{2}>\cdots>x_{k}\}$$ 

In order to show the weak convergence, it is sufficient to show that for every open set $O\in\mathbb{R}^{k}$, we have: 
$$\liminf_{T\rightarrow\infty}\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in O)\geqslant\int_{O}\rho(z_{1},\cdots,z_{k})dz_{1}dz_{2}\cdots dz_{k}$$
according to \cite[Theorem 3.2.11]{Durrett}. Actually, it suffices to show for any open set $U\in\mathbb{W}_{k}^{o}$, we have:
\begin{align}{\label{WeakConv}}
	\liminf_{T\rightarrow\infty}\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in U)\geqslant\int_{U}\rho(z_{1},\cdots,z_{k})dz_{1}dz_{2}\cdots dz_{k}
\end{align}
which implies that:
\begin{align*}
	&\liminf_{T\rightarrow\infty}\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in O)\geqslant\liminf_{T\rightarrow\infty}\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in O\cap\mathbb{W}_{k}^{o})\\
	&\geqslant \int_{\mathbb{W}_{k}^{o}\cap O}\rho(z_{1},\cdots,z_{k})dz_{1}\cdots dz_{k}= \int_{O}\rho(z_{1},\cdots,z_{N})dz_{1}\cdots dz_{k}
\end{align*}
The second inequality uses the above result \ref{WeakConv}, since $\mathbb{W}_{k}^{o}\cap O$ is an open set in $\mathbb{W}_{k}^{o}$. The last equality is because $\rho(z)$ is zero outside the $\mathbb{W}_{k}^{o}$. The rest of Part 2 will be divided into $4$ steps. In Step 1 and Step 2, we prove the result \ref{WeakConv} assuming the validity of a claim. In Step 3, we prove that $\rho(z)$ is actually a density. In Step 4, we prove the claim we made in Step 1.\\
\textbf{Step 1. }In this step, we establish the following result:\\
For any closed rectangle $R=[u_{1},v_{1}]\times [u_{2},v_{2}]\times\cdots\times[u_{k},v_{k}]\in\mathbb{W}_{k}^{o}$, 
\begin{align}
	\lim_{T\rightarrow\infty}\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in R)=\int_{R}\rho(z_{1},\cdots,z_{k})dz_{1}\cdots dz_{k}
\end{align}
where $\rho(z)$ is given in result $(2)$.\\

Define $m_{i}^{T}=\lceil u_{i}\sqrt{T}+ptT\rceil$ and $M_{i}^{T}=\lfloor v_{i}\sqrt{T}+ptT\rfloor$, and we have:
\begin{align*}
&\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in R)=\mathbb{P}(u_{1}\leqslant Z_{1}^{T} \leqslant v_{1}, \dots,  u_{k}\leqslant Z_{k}^{T} \leqslant v_{k})\\
&=\mathbb{P}(u_{i}\sqrt{T}+ptT\leqslant L_{i}(\lfloor tT\rfloor) \leqslant v_{i}\sqrt{T}+ptT, i=1,\dots, k)\\
&=\sum_{\lambda_{1}(T)=m_{1}^{T}}^{M_{1}^{T}}\cdots\sum_{\lambda_{k}(T)=m_{k}^{T}}^{M_{k}^{T}}\mathbb{P}(L_{1}(\lfloor tT \rfloor)=\lambda_{1}(T),\dots,L_{k}(\lfloor tT \rfloor)=\lambda_{k}(T))\\
&=\sum_{\lambda_{1}(T)=m_{1}^{T}}^{M_{1}^{T}}\dots\sum_{\lambda_{k}(T)=m_{k}^{T}}^{M_{k}^{T}}(\sqrt{T})^{-k}\cdot(\sqrt{T})^{k}\mathbb{P}(L_{1}(\lfloor tT \rfloor)=\lambda_{1}(T),\dots,L_{k}(\lfloor tT \rfloor)=\lambda_{k}(T))
\end{align*}

Find sufficiently large $A$ such that $R\subset[-A,A]^{k}$, for example, $A=1+\max_{1\leqslant i\leqslant k}|a_{i}|+\max_{1\leqslant i\leqslant k}|b_{i}|$. Define $f_{T}(z_{1},\cdots,z_{k})$ as a simple function on $\mathbb{R}^{k}$: When $(z_{1},\cdots,z_{k})\in R$, it takes value $(\sqrt{T})^{k}\mathbb{P}(L_{1}(\lfloor tT \rfloor)=\lambda_{1}(T),\cdots,L_{k}(\lfloor tT \rfloor)=\lambda_{k}(T)) $ if there exist $\lambda_{1}(T),\cdots,\lambda_{k}(T)$ such that $\lambda_{i}(T)\leqslant z_{i}\sqrt{T}+ptT<\lambda_{i}(T)+1$; It takes value $0$ otherwise, when $(z_{1},\cdots,z_{k})\notin R$.  Since the Lebesgue measure of the set $\{z:\lambda_{i}(T)\leqslant z_{i}\sqrt{T}+ptT<\lambda_{i}(T)+1,i=1,\cdots,k\}$ is $(\sqrt{T})^{-k}$, the above probability can be further written as an integral of simple function $f_{T}(z_{1},\cdots,z_{k})$:
\begin{align*}
\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in R)&=\int_{[-A,A]^{k}}f_{T}(z_{1},\cdots,z_{k})dz_{1}\cdots dz_{k}
\end{align*}
Now we introduce the following claim:\\
\textbf{Claim: }Fix $A>0$, take $z=(z_{1},\cdots,z_{k})\in\mathbb{W}_{k}^{o}$ such that $A>z_{1}>\cdots>z_{k}>-A$. Choose sufficiently large $T_{0}$ such that $ptT_{0}-A\sqrt{T_{0}}\geqslant 1$, then for $T\geqslant T_{0}$, define $\lambda_{i}(T)=\lfloor z_{i}\sqrt{T}+ptT\rfloor\geqslant 1$ for $i=1,\cdots,k$. Then we have for almost every $z\in[-A,A]^{k}$:
$$\lim_{T\rightarrow\infty}f_{T}(z_{1},\cdots,z_{k})=\rho(z_{1},\cdots,z_{k})$$ and $f_{T}(z_{1},\cdots,z_{k})$ is bounded on $[-A,A]^{k}$.\\
The proof of this claim is postponed to Step 4. For now, we assume the validity of the claim. Since the function $f_{T}(z_{1},\cdots,z_{k})$ is bounded on the compact set $[-A,A]^{k}$, and the Lebesgue measure of $[-A,A]^{k}$ is finite, by bounded convergence theorem and assuming the validity of the claim, we have:
$$\lim_{T\rightarrow\infty}\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in R)=\int_{R}\rho(z_{1},\cdots,z_{k})dz_{1}\cdots dz_{k}$$
\textbf{Step 2. }In this step, we prove the statement \ref{WeakConv}. Take any open set $U\in \mathbb{W}_{k}^{o}$, it can be written as a countable union of closed rectangles with disjoint interiors: $U=\bigcup_{i=1}^{\infty}R_{i}$, where $R_{i}=[a_{1}^{i},b_{1}^{i}]\times\cdots\times[a_{k}^{i},b_{k}^{i}]$(\cite[Theorem 1.4]{Stein}). Choose sufficiently small $\epsilon>0$, and denote $R_{i}^{\epsilon}=[a_{1}^{i}+\epsilon,b_{1}^{i}-\epsilon]\times\cdots\times[a_{k}^{i}+\epsilon,b_{k}^{i}-\epsilon]$, then $R_{i}^{\epsilon}$ are disjoint. Therefore,
\begin{align*}
	&\liminf_{T\rightarrow\infty}\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in U)\geqslant\liminf_{T\rightarrow\infty}\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in \bigcup_{i=1}^{n}R_{i}^{\epsilon})\\
	&=\liminf_{T\rightarrow\infty}\sum_{i=1}^{n}\mathbb{P}((Z_{1}^{T},\cdots,Z_{k}^{T})\in R_{i}^{\epsilon})=\sum_{i=1}^{n}\int_{R_{i}^{\epsilon}}\rho(z_1,\cdots,z_{k})dz_{1}\cdots dz_{k}\\
	&=\int_{\bigcup_{i=1}^{n}R_{i}^{\epsilon}}\rho(z_1,\cdots,z_{k})dz_{1}\cdots dz_{k} \W
