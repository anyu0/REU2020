%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
% Appendix A
%
%-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

\section{Appendix A} \label{AppendixA}

\subsection{Proof of Lemma \ref{Polish}}

Observe that the sets $K_1\subset K_2\subset\cdots\subset\Sigma\times\Lambda$ are compact, they cover $\Sigma\times\Lambda$, and any compact subset $K$ of $\Sigma\times\Lambda$ is contained in all $K_n$ for sufficiently large $n$. To see this last fact, let $\pi_1,\pi_2$ denote the canonical projection maps of $\Sigma\times\Lambda$ onto $\Sigma$ and $\Lambda$ respectively. Since these maps are continuous, $\pi_1(K)$ and $\pi_2(K)$ are compact in $\Sigma$ and $\Lambda$. This implies that $\pi_1(K)$ is finite, so it is contained in $\Sigma_{n_1} = \Sigma\cap\llbracket -n_1,n_1\rrbracket$ for some $n_1$. On the other hand, $\pi_2(K)$ is closed and bounded in $\mathbb{R}$, thus contained in some closed interval $[\alpha,\beta]\subseteq\Lambda$. Since $a_n\searrow a$ and $b_n\nearrow b$, we can choose $n_2$ large enough so that $\pi_2(K)\subseteq[\alpha,\beta]\subseteq[a_{n_2},b_{n_2}]$. Then taking $n=\max(n_1,n_2)$, we have $K \subseteq \pi_1(K) \times \pi_2(K) \subseteq \Sigma_n \times [a_n,b_n] = K_n$.

We now split the proof into several steps.\\

\noindent\textbf{Step 1.} In this step, we show that the function $d$ defined in the statement of the lemma is a metric. For each $n$ and $f,g\in C(\Sigma\times\Lambda)$, we define
\[
d_n(f,g) := \sup_{(i,t)\in K_n} |f(i,t)-g(i,t)|,\quad d_n'(f,g) := \min\{d_n(f,g), 1\} 
\]
Then we have
\[
d(f,g) = \sum_{n=1}^\infty 2^{-n} d_n'(f,g).
\]
Clearly each $d_n$ is nonnegative and satisfies the triangle inequality, and it is then easy to see that the same properties hold for $d_n'$. Furthermore, $d_n'\leq 1$, so $d$ is well-defined. Observe that $d$ is nonnegative, and if $f=g$, then each $d_n'(f,g)=0$, so the sum $d(f,g)$ is 0. Conversely, if $f\neq g$, then since the $K_n$ cover $\Sigma\times\Lambda$, we can choose $n$ large enough so that $K_n$ contains an $x$ with $f(x)\neq g(x)$. Then $d_n'(f,g)\neq 0$, and hence $d(f,g)\neq 0$. Lastly, the triangle inequality holds for $d$ since it holds for each $d_n'$.\\

\noindent\textbf{Step 2.} Now we prove that the topology $\tau_d$ on $C(\Sigma\times\Lambda)$ induced by $d$ is the same as the topology of uniform convergence over compacts, which we denote by $\tau_c$. Recall that $\tau_c$ is generated by the basis consisting of sets
\[
B_K(f,\epsilon) = \Big\{g\in C(\Sigma\times\Lambda) : \sup_{(i,t)\in K} |f(i,t) - g(i,t)| < \epsilon \Big\},
\]
for $K\subset\Sigma\times\Lambda$ compact, $f\in C(\Sigma\times\Lambda)$, and $\epsilon>0$, and $\tau_d$ is generated by sets of the form $B^d_\epsilon(f) = \{g:d(f,g) < \epsilon\}$. 

We first show that $\tau_d \subseteq \tau_c$. It suffices to prove that every set $B_\epsilon^d(f)$ is a union of sets $B_K(f,\epsilon)$. First, choose $\epsilon>0$ and $f\in C(\Sigma\times\Lambda)$. Let $g\in B^d_\epsilon(f)$. We will find a basis element $A_g$ of $\tau_c$ such that $g\in A_g\subset B^d_\epsilon(f)$. Let $\delta = d(f,g) < \epsilon$, and choose $n$ large enough so that $\sum_{k>n} 2^{-k} < \frac{\epsilon-\delta}{2}$. Define $A_g = B_{K_n}(g,\frac{\epsilon-\delta}{n})$, and suppose $h\in A_g$. Then since $K_m\subseteq K_n$ for $m\leq n$, we have
\begin{align*}
d(f,h) &\leq d(f,g) + d(g,h) \leq \delta + \sum_{k=1}^n 2^{-k}d_n(g,h) + \sum_{k>n} 2^{-k} \leq \delta + \frac{\epsilon-\delta}{2} + \frac{\epsilon-\delta}{2} = \epsilon.
\end{align*}
Therefore $g\in A_g\subset B^d_\epsilon(f)$. Then we can write
\[
B^d_\epsilon(f) = \bigcup_{g\in B^d_\epsilon(f)} A_g,
\]
a union of basis elements of $\tau_c$.

We now prove conversely that $\tau_c\subseteq\tau_d$. Let $K\subset\Sigma\times\Lambda$ be compact, $f\in C(\Sigma\times\Lambda)$, and $\epsilon>0$. Choose $n$ so that $K\subset K_n$, and let $g\in B_K(f,\epsilon)$ and $\delta = \sup_{x\in K} |f(x)-g(x)| < \epsilon$. If $d(g,h) < 2^{-n}(\epsilon-\delta)$, then $d_n'(g,h) \leq 2^n d(g,h) < \epsilon-\delta$, hence $d_n(g,h) < \epsilon-\delta$, assuming without loss of generality that $\epsilon \leq 1$. It follows that
\begin{align*}
\sup_{x\in K} |f(x)-h(x)| &\leq \delta + \sup_{x\in K} |g(x)-h(x)| \leq \delta + d_n(g,h) \leq \delta + \epsilon-\delta = \epsilon.
\end{align*}
Thus $g\in B^d_{2^{-n}(\epsilon-\delta)}(g) \subset B_K(f,\epsilon)$, proving that $B_K(f,\epsilon)\in\tau_d$ by the same argument as above. We conclude that $\tau_d = \tau_c$.\\

\noindent\textbf{Step 3.} In this step, we show that $(C(\Sigma\times\Lambda), d)$ is a complete metric space. Let $\{f_n\}_{n\geq 1}$ be Cauchy with respect to $d$. Then we claim that $\{f_n\}$ must be Cauchy with respect to $d_n'$, on each $K_n$. This follows from the observation that $ d_n'(f_\ell, f_m) \leq 2^n d(f_\ell, f_m)$. Thus $\{f_n\}$ is Cauchy with respect to the uniform metric on each $K_n$, and hence converges uniformly to a continuous limit $f^{K_n}$ on each $K_n$ (see \cite[Theorem 7.15]{Rudin}). Since the pointwise limit must be unique at each $x\in \Sigma\times\Lambda$, we have $f^{K_n}(x) = f^{K_m}(x)$ if $x\in K_n\cap K_m$. Since $\bigcup K_n = \Sigma\times\Lambda$, we obtain a well-defined function $f$ on all of $\Sigma\times\Lambda$ given by $f(x)=\lim_{n\to\infty} f^{K_n}(x)$. We have $f\in C(\Sigma\times\Lambda)$ since $f|_{K_n} = f^{K_n}$ is continuous on $K_n$ for all $n$. Moreover, if $K\subset\Sigma\times\Lambda$ is compact and $n$ is large enough so that $K\subset K_n$, then because $f_n \to f^{K_n} = f|_{K_n}$ uniformly on $K_n$, we have $f_n \to f^{K_n}|_K = f|_K$ uniformly on $K$. That is, for any $K\subset\Sigma\times\Lambda$ compact and $\epsilon>0$, we have $f_n \in B_K(f,\epsilon)$ for all sufficiently large $n$. Therefore $f_n \to f$ in $\tau_c$, and equivalently in the metric $d$ by Step 2.\\

\noindent\textbf{Step 4.} Lastly, we prove separability, c.f. \cite[Example 1.3]{Billing}. For each pair of positive integers $n,k$, let $D_{n,k}$ be the subcollection of $C(\Sigma\times\Lambda)$ consisting of polygonal functions that are piecewise linear on $\{j\}\times I_{n,k,i}$ for each $j\in\Sigma_n$ and each subinterval 
\[
I_{n,k,i} := \big[a_n+\tfrac{i-1}{k}(b_n-a_n), \, a_n+\tfrac{i}{k}(b_n-a_n)\big], \quad 1\leq i\leq k,
\] 
taking rational values at the endpoints of these subintervals, and extended linearly to all of $\Lambda = [a,b]$. Then $D := \bigcup_{n,k} D_{n,k}$ is countable, and we claim that it is dense in $\tau_c$. To see this, let $K\subset\Sigma\times\Lambda$ be compact, $f\in C(\Sigma\times\Lambda)$, and $\epsilon>0$, and choose $n$ so that $K\subset K_n$. Since $f$ is uniformly continuous on $K_n$, we can choose $k$ large enough so that for $0\leq i\leq k$, if $t\in I_{n,k,i}$, then 
\[
\big|f(j,t) - f(j, a_n + \tfrac{i}{k}(b_n-a_n))\big| < \epsilon/2
\]
for all $j\in\Sigma_n$. We then choose $g\in \bigcup_k D_{n,k}$ with $|g(j,a_n + \frac{i}{k}(b_n-a_n)) - f(j,a_n + \frac{i}{k}(b_n-a_n))| < \epsilon/2$. Then we have 
\begin{align*}
	\big|f(j,t) - g(j, a_n + \tfrac{i-1}{k}(b_n-a_n))\big| < \epsilon \quad \mathrm{and} \quad \big|f(j,t) - g(j, a_n + \tfrac{i}{k}(b_n-a_n))\big| < \epsilon.
\end{align*}
Since $g(j, a_n + \tfrac{i-1}{k}(b_n-a_n)) \leq g(j,t) \leq g(j, a_n + \tfrac{i}{k}(b_n-a_n))$, it follows that 
\[
|f(j,t) - g(j,t)| < \epsilon
\]
as well. In summary,
\[
\sup_{(j,t)\in K} |f(j,t)-g(j,t)| \leq \sup_{(j,t)\in K_n} |f(j,t)-g(j,t)| < \epsilon,
\] 
so $g\in B_K(f,\epsilon)$. This proves that $D$ is a countable dense subset of $C(\Sigma\times\Lambda)$.


\subsection{Proof of Lemma \ref{2Tight}}

We first prove two lemmas that will be used in the proof of Lemma \ref{2Tight}. The first result allows us to identify the space $C(\Sigma\times\Lambda)$ with a product of copies of $C(\Lambda)$. In the following, we assume the notation of Lemma \ref{2Tight}.

\begin{lemma}\label{ProdTop}
	Let $\pi_i: C (\Sigma \times \Lambda) \rightarrow C(\Lambda)$, $i \in \Sigma$, be the projection maps given by
	$\pi_i(F)(x) = F(i, x)$ for $x \in \Lambda$. Then the $\pi_i$ are continuous. Endow the space $\prod_{i\in\Sigma} C(\Lambda)$ with the product topology induced by the topology of uniform convergence over compacts on $C(\Lambda)$. Then the mapping
	\begin{align*}
		F : C(\Sigma\times\Lambda) \longrightarrow \prod_{i\in\Sigma} C(\Lambda), \quad f\mapsto (\pi_i(f))_{i\in\Sigma}
	\end{align*}
	is a homeomorphism.
\end{lemma}

\begin{proof}
	We first prove that the $\pi_i$ are continuous. Since $C(\Sigma\times\Lambda)$ is metrizable by Lemma \ref{Polish}, and by a similar argument so is $C(\Lambda)$, it suffices to assume that $f_n\to f$ in $C(\Sigma\times\Lambda)$ and show that $\pi_i(f_n)\to \pi_i(f)$ in $C(\Lambda)$. Let $K$ be compact in $\Lambda$. Then $\{i\}\times K$ is compact in $\Sigma\times\Lambda$, and $f_n\to f$ on $\{i\}\times K$ by assumption, so we have $\pi_i(f_n)|_K = f_n|_{\{i\}\times K} \to f|_{\{i\}\times K} = \pi_i(f)|_K$ uniformly on $K$. Since $K$ was arbitrary, we conclude that $\pi_i(f_n) \to \pi_i(f)$ in $C(\Lambda)$ as desired. 
	
	We now observe that $F$ is invertible. If $(f_i)_{i\in\Sigma} \in \prod_{i\in\Sigma} C(\Lambda)$, then the function $f$ defined by $f(i,\cdot) = f_i(\cdot)$ is in $C(\Sigma\times\Lambda)$, since $\Sigma$ has the discrete topology. This gives a well-defined inverse for $F$. It suffices to prove that $F$ and $F^{-1}$ are open maps.
	
	We first show that $F$ sends each basis element $B_K(f,\epsilon)$ of $C(\Sigma\times\Lambda)$ to a basis element in $\prod_{i\in\Sigma} C(\Lambda)$. Note that a basis for the product topology is given by products $\prod_{i\in\Sigma} B_{K_i}(f_i,\epsilon)$, where at most finitely many of the $K_i$ are nonempty. Here, we use the convention that $B_{\varnothing}(f_i,\epsilon) = C(\Lambda)$. Let $\pi_\Sigma,\pi_\Lambda$ denote the canonical projections of $\Sigma\times\Lambda$ onto $\Sigma,\Lambda$. The continuity of $\pi_\Sigma$ implies that if $K\subset\Sigma\times\Lambda$ is compact, then $\pi_\Sigma(K)$ is compact in $\Sigma$, hence finite. Observe that the set $K\cap(\{i\}\times\Lambda)$ is an intersection of two compacts sets, hence compact in $\Sigma\times\Lambda$. Therefore the sets $K_i = \pi_\Lambda(K\cap(\{i\}\times\Lambda))$ are compact in $\Lambda$ for each $i\in\Sigma$ since $\pi_\Lambda$ is continuous. We observe that $F(B_K(f,\epsilon)) = \prod_{i\in\Sigma} U_i$, where
	\[
	U_i = B_{K_i}(\pi_i(f),\epsilon), \quad\mathrm{if} \quad i \in \pi_\Sigma(K),
	\]
	and $U_i = C(\Lambda)$ otherwise. Since $\pi_\Sigma(K)$ is finite and the $K_i$ are compact, we see that $F(B_K(f,\epsilon))$ is a basis element in the product topology as claimed.
	
	Lastly, we show that $F^{-1}$ sends each basis element $U = \prod_{i\in\Sigma} B_{K_i}(f_i,\epsilon)$ for the product topology to a set of the form $B_K(f,\epsilon)$. We have $K_i=\varnothing$ for all but finitely many $i$. Write $f = F^{-1}((f_i)_{i\in\Sigma})$ and $K=\prod_{i\in\Sigma} K_i$. By Tychonoff's theorem, \cite[Theorem 37.3]{Munkres}, $K$ is compact in $\Sigma\times\Lambda$, and
	\[
	F^{-1}(U) = B_K(f,\epsilon).
	\]
	
\end{proof}

We next prove a lemma which states that a sequence of line ensembles is tight if and only if all individual curves form tight sequences.

\begin{lemma}\label{ProjTight}
	Suppose that $\{\mathcal{L}^n\}_{n\geq 1}$ is a sequence of $\Sigma$-indexed line ensembles on $\Lambda$, and let $X_i^n = \pi_i(\mathcal{L}^n)$. Then the $X_i^n$ are $C(\Lambda)$-valued random variables on $(\Omega,\mathcal{F},\mathbb{P})$, and $\{\mathcal{L}^n\}$ is tight if and only if for each $i \in \Sigma$ the sequence $\{X_i^n\}_{n\geq 1}$ is tight.
	
\end{lemma}

\begin{proof}

The fact that the $X_i^n$ are random variables follows from the continuity of the $\pi_i$ in Lemma \ref{ProdTop} and \cite[Theorem 1.3.5]{Durrett}. First suppose the sequence $\{\mathcal{L}^n\}$ is tight. By Lemma \ref{Polish}, $C(\Sigma\times\Lambda)$ is a Polish space, so it follows from Prohorov's theorem, \cite[Theorem 5.1]{Billing}, that $\{\mathcal{L}^n\}$ is relatively compact. That is, every subsequence $\{\mathcal{L}^{n_k}\}$ has a further subsequence $\{\mathcal{L}^{n_{k_\ell}}\}$ converging weakly to some $\mathcal{L}$. Then for each $i\in\Sigma$, since $\pi_i$ is continuous by the above, the subsequence $\{\pi_i(\mathcal{L}^{n_{k_\ell}})\}$ of $\{\pi_i(\mathcal{L}^{n_k})\}$ converges weakly to $\pi_i(\mathcal{L})$ by the continuous mapping theorem, \cite[Theorem 3.2.10]{Durrett}. Thus every subsequence of $\{\pi_i(\mathcal{L}^n)\}$ has a convergent subsequence. Since $C(\Lambda)$ is a Polish space by the same argument as in the proof of Lemma \ref{Polish}, Prohorov's theorem implies that each $\{\pi_i(\mathcal{L}^n)\}$ is tight.

Conversely, suppose $\{X_i^n\}$ is tight for all $i\in\Sigma$. Then given $\epsilon > 0$, we can find compact sets $K_i\subset C(\Lambda)$ such that
\[
\mathbb{P}(X_i^n \notin K_i) \leq \epsilon/2^i
\]
for each $i\in\Sigma$. By Tychonoff's theorem, \cite[Theorem 37.3]{Munkres}, the product $\tilde{K} = \prod_{i\in\Sigma} K_i$ is compact in $\prod_{i\in\Sigma} C(\Lambda)$. We have
\begin{equation}\label{tychonoff}
\mathbb{P}\big((X_i^n)_{i\in\Sigma} \notin \tilde{K} \big) \leq \sum_{i\in\Sigma} \mathbb{P}(X_i^n \notin K_i) \leq \sum_{i=1}^\infty \epsilon/2^i = \epsilon.
\end{equation}
By Lemma \ref{ProdTop}, we have a homeomorphism $G : \prod_{i\in\Sigma} C(\Lambda) \to C(\Sigma\times\Lambda)$. We observe that $G((X_i^n)_{i\in\Sigma}) = \mathcal{L}^n$, and $K = G(\tilde{K})$ is compact in $C(\Sigma\times\Lambda)$. Thus $\mathcal{L}^n \in K$ if and only if $(X_i^n)_{i\in\Sigma} \in \tilde{K}$, and it follows from \eqref{tychonoff} that
\[
\mathbb{P}(\mathcal{L}^n \in K) \geq 1 - \epsilon.
\]
This proves that $\{\mathcal{L}^n\}$ is tight.

\end{proof}

We are now ready to prove Lemma \ref{2Tight}.

\begin{proof}
	
Fix an $i\in\Sigma$. By Lemma \ref{ProjTight}, it suffices to show that the sequence $\{\mathcal{L}_i^n\}_{n\geq 1}$ of $C(\Lambda)$-valued random variables is tight. By \cite[Theorem 7.3]{Billing}, a sequence $\{P_n\}$ of probability measures on $C[0,1]$ with the uniform topology is tight if and only if the following conditions hold:
\begin{align*}
\lim_{a\to\infty} \limsup_{n\to\infty} P_n(|x(0)|\geq a) &= 0, \\
\lim_{\delta\to 0} \limsup_{n\to\infty} P_n\Big(\sup_{|s-t|\leq\delta} |x(s)-x(t)| \geq \epsilon\Big) &= 0 \quad \textrm{for all}\;\epsilon>0.
\end{align*}
By replacing $[0,1]$ with $[a_m,b_m]$ and 0 with $a_0$, we see that the hypotheses in the lemma imply that the sequence $\{\mathcal{L}_i^n|_{[a_m,b_m]}\}_n$ is tight for every $m\geq 1$. Let $\pi_m : C(\Lambda) \to C([a_m,b_m])$ denote the map $f \mapsto f|_{[a_m,b_m]}$. Then $\pi_m$ is continuous, since $C(\Lambda)$ and $C([a_m,b_m])$ with the topologies of uniform convergence over compacts are metrizable by Lemma \ref{Polish}, and if $f_n\to f$ uniformly on compact subsets of $\Lambda$, then $f_n|_{[a_m,b_m]} \to f|_{[a_m,b_m]}$ uniformly on compact subsets of $[a_m,b_m]$. It follows from \cite[Theorem 1.3.5]{Durrett} that $\pi_m(\mathcal{L}^n) = \mathcal{L}_i^n|_{[a_m,b_m]}$ is a $C([a_m,b_m])$-valued random variable. Tightness of the sequence implies that for any $\epsilon > 0$, we can find compact sets $K_m\subset C([a_m,b_m])$ so that
\[
\mathbb{P}\big(\pi_m(\mathcal{L}_i^n) \notin K_m \big) \leq \epsilon/2^m
\]
for each $m\geq 1$. Writing $K = \bigcap_{m=1}^\infty \pi_m^{-1}(K_m)$, it follows that
\[
\mathbb{P}\big(\mathcal{L}^n_i \in K\big) \geq 1 - \sum_{m=1}^\infty \epsilon/2^m = 1 - \epsilon.
\]
To conclude tightness of $\{\mathcal{L}_i^n\}$, it suffices to prove that $K = \bigcap_{m=1}^\infty \pi_m^{-1}(K_m)$ is sequentially compact in $C(\Lambda)$. We argue by diagonalization. Let $\{f_n\}$ be a sequence in $K$, so that $f_n|_{[a_m,b_m]} \in K_m$ for every $m,n$. Since $K_1$ is compact, there is a sequence $\{n_{1,k}\}$ of natural numbers such that the subsequence $\{f_{n_{1,k}}|_{[a_1,b_1]}\}_k$ converges in $C([a_1,b_1])$. Since $K_2$ is compact, we can take a further subsequence $\{n_{2,k}\}$ of $\{n_{1,k}\}$ so that $\{f_{n_{2,k}}|_{[a_2,b_2]}\}_k$ converges in $C([a_2,b_2])$. Continuing in this manner, we obtain sequences $\{n_{1,k}\} \supseteq \{n_{2,k}\} \supseteq\cdots$ so that $\{f_{n_{m,k}}|_{[a_m,b_m]}\}_k$ converges in $C([a_m,b_m])$ for all $m$. Writing $n_k = n_{k,k}$, it follows that the sequence $\{f_{n_k}\}$ converges uniformly on each $[a_m,b_m]$. If $K$ is any compact subset of $C(\Lambda)$, then $K\subset [a_m,b_m]$ for some $m$, and hence $\{f_{n_k}\}$ converges uniformly on $K$. Therefore $\{f_{n_k}\}$ is a convergent subsequence of $\{f_n\}$.

\end{proof}


\subsection{Proof of Lemmas \ref{MCLxy} and \ref{MCLfg}}

We will prove the following lemma, of which the two lemmas are immediate consequences. In particular, Lemma \ref{MCLxy} is the special case when $g^b = g^t$, and Lemma \ref{MCLfg} is the case when $\vec{x} = \vec{x}\,'$ and $\vec{y} = \vec{y}\,'$. We argue in analogy to \cite[Lemma 5.6]{DimMat}.

\begin{lemma}
	Fix $k \in \mathbb{N}$, $T_0, T_1 \in \mathbb{Z}$ with $T_0 < T_1$, and two functions $g^b, g^t: \llbracket T_0, T_1 \rrbracket  \rightarrow [-\infty, \infty)$ with $g^b\leq g^t$. Also fix $\vec{x}, \vec{y}, \vec{x}\,', \vec{y}\,' \in \mathfrak{W}_k$, such that $g^b(T_0)\leq x_i$, $g^b(T_1)\leq y_i$, $g^t(T_0)\leq x_i'$, $g^t(T_1)\leq y_i'$, and $x_i\leq x_i'$, $y_i\leq y_i'$ for $1\leq i\leq k$. Assume that $\Omega_{avoid}(T_0, T_1, \vec{x}, \vec{y}, \infty,g^b)$ and $\Omega_{avoid}(T_0, T_1, \vec{x}\,', \vec{y}\,', \infty,g^t)$ are both non-empty. Then there exists a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, which supports two $\llbracket 1, k \rrbracket$-indexed Bernoulli line ensembles $\mathfrak{L}^t$ and $\mathfrak{L}^b$ on $\llbracket T_0, T_1 \rrbracket$ such that the law of $\mathfrak{L}^{t}$ {\big (}resp. $\mathfrak{L}^b${\big )} under $\mathbb{P}$ is given by $\mathbb{P}_{avoid, Ber}^{T_0, T_1, \vec{x}\,', \vec{y}\,', \infty, g^t}$ {\big (}resp. $\mathbb{P}_{avoid, Ber}^{T_0, T_1, \vec{x}, \vec{y}, \infty, g^b}${\big )} and such that $\mathbb{P}$-almost surely we have $\mathfrak{L}_i^t(r) \geq \mathfrak{L}^b_i(r)$ for all $i = 1,\dots, k$ and $r \in \llbracket T_0, T_1 \rrbracket$.
\end{lemma}

\begin{proof} We split the proof into two steps.\\
	
	\noindent\textbf{Step 1.} We first aim to construct a Markov chain $(X^n,Y^n)_{n\geq 0}$, with \\$X^n\in \Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)$, $Y^n\in \Omega_{avoid}(T_0,T_1,\vec{x}\,',\vec{y}\,',\infty,g^t)$, with initial distribution given by the maximal paths
	\begin{align*}
	& X^0_1(t)=(x_1+t-T_0) \wedge y_1,\quad && Y^0_1(t)=(x_1'+t-T_0) \wedge y_1'\\
	& X^0_k(t)=(x_k+t-T_0) \wedge y_k \wedge X^0_{k-1}(t), \quad && Y^0_k(t)=(x_k'+t-T_0) \wedge y_k' \wedge Y^0_{k-1}(t).
	\end{align*}
	for $t\in\llbracket T_0, T_1\rrbracket$. We want this chain to have the following properties: 
	\begin{enumerate}[label=(\arabic*)]
		
		\item $(X^n)_{n\geq 0}$ and $(Y^n)_{n\geq 0}$ are both Markov in their own filtrations,
		
		\item $(X^n)$ is irreducible and has as an invariant distribution the uniform measure $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x},\vec{y},\infty,g^b}$,
		
		\item $(Y^n)$ is irreducible and has invariant distribution $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x}',\vec{y}',\infty,g^t}$,
		
		\item $X^n_i\leq Y^n_i$ on $\llbracket T_0, T_1\rrbracket$ for all $n\geq 0$ and $1\leq i \leq k$.
		
	\end{enumerate}
	
	\noindent This will allow us to conclude convergence of $X^n$ and $Y^n$ to these two uniform measures.
	
	We specify the dynamics of $(X^n, Y^n)$ as follows. At time $n$, we uniformly sample a segment $\{t\}\times[z, z+1]$, with $t\in\llbracket T_0, T_1\rrbracket$ and $z\in\llbracket x_k,y_1'-1\rrbracket$. We also flip a fair coin, with $\mathbb{P}(\textrm{heads})=\mathbb{P}(\textrm{tails})=1/2$. We update $X^n$ and $Y^n$ using the following procedure. For all points $s\neq t$, we set $X^{n+1}(s) = X^n(s)$. If $T_0 < t < T_1$ and $X^n_i(t-1)=z$ and $X^n_i(t+1)=z+1$ (note that this implies $X^n_i(t)\in\{z,z+1\}$), then we set
	\[
	X^{n+1}_i(t) = \begin{cases}
	z+1, & \textrm{if heads},\\
	z, & \textrm{if tails},
	\end{cases}
	\]
	assuming that this move does not cause $X^{n+1}_i(t)$ to fall below $g^b(t)$. In all other cases, we leave $X^{n+1}_i(t)=X^n_i(t)$. We update $Y^n$ using the same rule, with $g^t$ in place of $g^b$. [Maybe add a figure here.] We will verify below in the proof of (4) that $X^n$ and $Y^n$ are in fact non-intersecting for all $n$, but we assume this for now.
	
	It is easy to see that $(X^n,Y^n)$ is a Markov chain, since at each time $n$, the value of $(X^{n+1},Y^{n+1})$ depends only on the current state $(X^n,Y^n)$, and not on the time $n$ or any of the states prior to time $n$. Moreover, the value of $X^{n+1}$ depends only on the state $X^n$, not on $Y^n$, so $(X^n)$ is a Markov chain in its own filtration. The same applies to $(Y^n)$. This proves the property (1) above.
	
	We now argue that $(X^n)$ is each irreducible. Observe that the initial distribution $X^0$ is by construction maximal, in the sense that for any $Z\in \Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)$, we have $Z_i \leq X^0_i$ for all $i$. Thus to reach $Z$ from the initial state $X_0$, we only need to move the paths downward, and there is no danger of the paths $X_i$ crossing when we do so. We start by ensuring $X^n_k = Z_k$. We successively sample segments which touch $Z_k$ at each point in $\llbracket T_0,T_1\rrbracket$ where $Z_k$ differs from $X_k$, and choose the appropriate coin flips until the two agree on all of $\llbracket a,b\rrbracket$. We repeat this procedure for $X^n_i$ and $Z^i$, with $i$ descending. Since each of these samples and flips has positive probability, and this process terminates in finitely many steps, the probability of transitioning from $X^n$ to $Z$ after some number of steps is positive. The same reasoning applies to show that $(Y^n)$ is irreducible.
	
	To see that the uniform measure $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x},\vec{y},\infty,g^b}$ on $\Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)$ is invariant for $(X^n)$, fix any line ensemble $\omega\in\Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)$. For simplicity, write $\mu$ for the uniform measure and $N=|\Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)|$ for the (finite) number of allowable ensembles. Then for all ensembles $\tau\in\Omega_{avoid}(T_0,T_1,\vec{x},\vec{y},\infty,g^b)$, $\mu(\tau) = 1/N$. Hence
	\begin{align*}
	& \sum_\tau \mu(\tau)\mathbb{P}(X^{n+1} = \omega\,|\,X^n = \tau) = \frac{1}{N}\sum_\tau \mathbb{P}(X^{n+1} = \omega\,|\,X^n = \tau)\\
	= \; & \frac{1}{N}\sum_\tau \mathbb{P}(X^{n+1} = \tau\,|\,X^n = \omega) = \frac{1}{N}\cdot 1 = \mu(\omega).
	\end{align*}
	The second equality is clear if $\tau=\omega$. Otherwise, note that $\mathbb{P}(X_{n+1} = \omega\,|\,X_n = \tau) \neq 0$ if and only if $\tau$ and $\omega$ differ only in one indexed path (say the $i$th) at one point $t$, where $|\tau_i(t)-\omega_i(t)|=1$, and this condition is also equivalent to $\mathbb{P}(X^{n+1} = \tau\,|\,X^n = \omega) \neq 0$. If $X^n=\tau$, there is exactly one choice of segment $\{t\}\times[z,z+1]$ and one coin flip which will ensure $X^{n+1}_i(t)=\omega(t)$, i.e., $X^{n+1}=\omega$. Conversely, if $X^n=\omega$, there is one segment and one coin flip which will ensure $X^{n+1}=\tau$. Since the segments are sampled uniformly and the coin flips are fair, these two conditional probabilities are in fact equal. This proves (2), and an analogous argument proves (3).
	
	Lastly, we argue that $X^n_i\leq Y^n_i$ for all $n\geq 0$ and $1\leq i\leq k$. The same argument will prove that $X^n_{i+1}\leq X^n_i$ for all $n,i$, so that $X^n$ is in fact non-intersecting for all $n$, and likewise for $Y^n$. This is of course true at $n=0$. Suppose it holds at some $n\geq 0$. Then since the update rule can only change the values of $X_i$ and $Y_i$ at a single point $t$, it suffices to look at the possible updates to the $i$th curve at a single point $t\in\llbracket T_0, T_1\rrbracket$. Notice that the update can only change values by at most 1, and if $Y^n_i(t) - X^n_i(t) = 1$, then the only way the ordering could be violated is if $Y_i$ were lowered and $X_i$ were raised at the next update. But this is impossible, since a coin flip of heads can only raise or leave fixed both curves, and tails can only lower or leave fixed both curves. Thus it suffices to assume $X^n_i(t) = Y^n_i(t)$. 
	
	There are two cases to consider that violate the ordering of $X^{n+1}_i(t)$ and $Y^{n+1}_i(t)$. Either (i) $X_i(t)$ is raised but $Y_i(t)$ is left fixed, or (ii) $Y_i(t)$ is lowered yet $X_i(t)$ is left fixed. These can only occur if the curves exhibit one of two specific shapes on $\llbracket t-1, t+1\rrbracket$. For $X_i(t)$ to be raised, we must have $X^n_i(t-1) = X^n_i(t) = X^n_i(t+1) - 1$, and for $Y_i(t)$ to be lowered, we must have $Y^n_i(t-1) - 1 = Y^n_i(t) = Y^n_i(t+1)$. From the assumptions that $X^n_i(t) = Y^n_i(t)$, and $X^n_i \leq Y^n_i$, we observe that both of these requirements force the other curve to exhibit the same shape on $\llbracket t-1, t+1\rrbracket$. Then the update rule will be the same for both curves, proving that both (i) and (ii) are impossible. \\
	
	\noindent\textbf{Step 2.} It follows from (2) and (3) and \cite[Theorem 1.8.3]{Norris} that $(X^n)_{n\geq 0}$ and $(Y^n)_{n\geq 0}$ converge weakly to $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x},\vec{y},\infty,g^b}$ and $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x}',\vec{y}',\infty,g^t}$ respectively. In particular, $(X^n)$ and $(Y^n)$ are tight, so $(X^n,Y^n)_{n\geq 0}$ is tight as well. By Prohorov's theorem, it follows that $(X^n,Y^n)$ is relatively compact. Let $(n_m)$ be a sequence such that $(X^{n_m},Y^{n_m})$ converges weakly. Then by the Skorohod representation theorem \cite[Theorem 6.7]{Billing}, it follows that there exists a probability space $(\Omega,\mathcal{F},\mathbb{P})$ supporting $C(\llbracket 1, k\rrbracket \times \llbracket T_0, T_1\rrbracket)$-valued random variables $\mathfrak{X}^n$, $\mathfrak{Y}^n$ and $\mathfrak{X},\mathfrak{Y}$ such that
	\begin{enumerate}[label=(\arabic*)]
		
		\item The law of $(\mathfrak{X}^n,\mathfrak{Y}^n)$ under $\mathbb{P}$ is the same as that of $(X^n,Y^n)$,
		
		\item $\mathfrak{X}^n(\omega) \longrightarrow \mathfrak{X}(\omega)$ for all $\omega\in\Omega$,
		
		\item $\mathfrak{Y}^n(\omega) \longrightarrow \mathfrak{Y}(\omega)$ for all $\omega\in\Omega$.
		
	\end{enumerate}
	
	In particular, (1) implies that $\mathfrak{X}^{n_m}$ has the same law as $X^{n_m}$, which converges weakly to $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x},\vec{y},\infty,g^b}$. It follows from (2) and the uniqueness of limits that $\mathfrak{X}$ has law $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x},\vec{y},\infty,g^b}$. Similarly, $\mathfrak{Y}$ has law $\mathbb{P}_{avoid,Ber}^{T_0,T_1,\vec{x}',\vec{y}',\infty,g^t}$. Moreover, condition (4) in Step 1 implies that $\mathfrak{X}^n_i \leq \mathfrak{Y}^n_i$, $\mathbb{P}$-a.s., so $\mathfrak{X}_i \leq \mathfrak{Y}_i$ for $1\leq i\leq k$, $\mathbb{P}$-a.s. Thus we can take $\mathfrak{L}^b := \mathfrak{X}$ and $\mathfrak{L}^t := \mathfrak{Y}$.
	
\end{proof}
